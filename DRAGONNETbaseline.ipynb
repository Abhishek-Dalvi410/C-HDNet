{"cells":[{"cell_type":"code","execution_count":2,"id":"05341e16","metadata":{"id":"05341e16","executionInfo":{"status":"ok","timestamp":1725482423736,"user_tz":240,"elapsed":4286,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["import numpy as np\n","import sys\n","import tensorflow as tf\n","from keras.losses import Loss\n","from sklearn.preprocessing import StandardScaler\n","from scipy.sparse import csr_matrix\n","import pandas as pd\n","import datetime\n","import time\n","import io\n","from sklearn.model_selection import train_test_split\n","import scipy.io as sio"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5n5czUDf6uE-","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":18138,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}},"outputId":"8ddb6e1a-1724-40b9-9ec0-adf136d6aba8"},"id":"5n5czUDf6uE-","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"id":"a940376d","metadata":{"id":"a940376d","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":8,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["def load_data(dataset, kappa, exp_id, original_X=False, extra_str=\"\"):\n","    path = '/content/drive/MyDrive/Causal_network_matching/data/'+dataset+str(kappa)+'/'+str(dataset)+''+str(exp_id)+'.mat'\n","    print(path)\n","    data = sio.loadmat(path)\n","    A = data['Network']  # csr matrix\n","\n","    if not original_X:\n","        X = data['X_100']\n","    else:\n","        X = data['Attributes']\n","\n","    mu_1 = data['Y1']\n","    mu_0 = data['Y0']\n","    T = data['T']\n","\n","    T = T.flatten()\n","    mu_1 = mu_1.flatten()\n","    mu_0 = mu_0.flatten()\n","\n","    Y_observed = []\n","    for i in range(len(T)):\n","        if T[i] == 1:\n","            Y_observed.append(mu_1[i])\n","        else:\n","            Y_observed.append(mu_0[i])\n","\n","    Y_observed = np.array(Y_observed)\n","    X = X.todense()\n","\n","\n","    X_train, X_test, Y_factual_train, _, T_train, _, mu_0_train, mu_0_test, mu_1_train, mu_1_test = train_test_split(X, Y_observed, T, mu_0, mu_1, test_size=0.2)\n","\n","    X_train = X_train.astype('float32')\n","    Y_factual_train = Y_factual_train.astype('float32') #most GPUs only compute 32-bit floats\n","    T_train = T_train.astype('float32')\n","    mu_0_train = mu_0_train.astype('float32')\n","    mu_1_train = mu_1_train.astype('float32')\n","\n","    X_test = X_test.astype('float32')\n","    mu_0_test = mu_0_test.astype('float32')\n","    mu_1_test = mu_1_test.astype('float32')\n","\n","    data_train={'x':X_train,'y':Y_factual_train,'t':T_train,'mu_0':mu_0_train,'mu_1':mu_1_train}\n","    data_train['t']=data_train['t'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension\n","    data_train['y']=data_train['y'].reshape(-1,1)\n","    data_train['mu_0']=data_train['mu_0'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension\n","    data_train['mu_1']=data_train['mu_1'].reshape(-1,1)\n","\n","    #rescaling y between 0 and 1 often makes training of DL regressors easier\n","    data_train['y_scaler'] = StandardScaler().fit(data_train['y'])\n","    data_train['ys'] = data_train['y_scaler'].transform(data_train['y'])\n","\n","    data_test={'x':X_test,'mu_0':mu_0_test,'mu_1':mu_1_test}\n","    data_test['y_scaler'] = data_train['y_scaler']\n","    data_test['mu_0']=data_test['mu_0'].reshape(-1,1) #we're just padding one dimensional vectors with an additional dimension\n","    data_test['mu_1']=data_test['mu_1'].reshape(-1,1)\n","\n","    return data_train, data_test"]},{"cell_type":"code","execution_count":5,"id":"ab1741a4","metadata":{"id":"ab1741a4","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":6,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Concatenate\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import Model\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow.keras.metrics import binary_accuracy\n","from tensorflow.keras.losses import Loss\n","class EpsilonLayer(Layer):\n","\n","    def __init__(self):\n","        super(EpsilonLayer, self).__init__()\n","\n","    def build(self, input_shape):\n","        # Create a trainable weight variable for this layer.\n","        self.epsilon = self.add_weight(name='epsilon',\n","                                       shape=[1, 1],\n","                                       initializer='RandomNormal',\n","                                       #  initializer='ones',\n","                                       trainable=True)\n","        super(EpsilonLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, **kwargs):\n","        #note there is only one epsilon were just duplicating it for conformability\n","        return self.epsilon * tf.ones_like(inputs)[:, 0:1]\n","\n","def make_dragonnet(input_dim, reg_l2):\n","\n","    x = Input(shape=(input_dim,), name='input')\n","    # representation\n","    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(x)\n","    phi = Dense(units=200, activation='elu', kernel_initializer='RandomNormal',name='phi_2')(phi)\n","\n","    # HYPOTHESIS\n","    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n","    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n","\n","    # second layer\n","    y0_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_2')(y0_hidden)\n","    y1_hidden = Dense(units=100, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_2')(y1_hidden)\n","\n","    # third\n","    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n","    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n","\n","    #propensity prediction\n","    #Note that the activation is actually sigmoid, but we will squish it in the loss function for numerical stability reasons\n","    t_predictions = Dense(units=1,activation=None,name='t_prediction')(phi)\n","    #Although the epsilon layer takes an input, it really just houses a free parameter.\n","    epsilons = EpsilonLayer()(t_predictions)\n","    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,t_predictions,epsilons,phi])\n","    model = Model(inputs=x, outputs=concat_pred)\n","    return model\n"]},{"cell_type":"code","execution_count":6,"id":"efd96b67","metadata":{"id":"efd96b67","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":6,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["class Base_Loss(Loss):\n","    #initialize instance attributes\n","    def __init__(self, alpha=1.0):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.name='standard_loss'\n","\n","    def split_pred(self,concat_pred):\n","        #generic helper to make sure we dont make mistakes\n","        preds={}\n","        preds['y0_pred'] = concat_pred[:, 0]\n","        preds['y1_pred'] = concat_pred[:, 1]\n","        preds['t_pred'] = concat_pred[:, 2]\n","        preds['phi'] = concat_pred[:, 3:]\n","        return preds\n","\n","    #for logging purposes only\n","    def treatment_acc(self,concat_true,concat_pred):\n","        t_true = concat_true[:, 1]\n","        p = self.split_pred(concat_pred)\n","        #Since this isn't used as a loss, I've used tf.reduce_mean for interpretability\n","        return tf.reduce_mean(binary_accuracy(t_true, tf.math.sigmoid(p['t_pred']), threshold=0.5))\n","\n","    def treatment_bce(self,concat_true,concat_pred):\n","        t_true = concat_true[:, 1]\n","        p = self.split_pred(concat_pred)\n","        lossP = tf.reduce_sum(binary_crossentropy(t_true,p['t_pred'],from_logits=True))\n","        return lossP\n","\n","    def regression_loss(self,concat_true,concat_pred):\n","        y_true = concat_true[:, 0]\n","        t_true = concat_true[:, 1]\n","        p = self.split_pred(concat_pred)\n","        loss0 = tf.reduce_sum((1. - t_true) * tf.square(y_true - p['y0_pred']))\n","        loss1 = tf.reduce_sum(t_true * tf.square(y_true - p['y1_pred']))\n","        return loss0+loss1\n","\n","    def standard_loss(self,concat_true,concat_pred):\n","        lossR = self.regression_loss(concat_true,concat_pred)\n","        lossP = self.treatment_bce(concat_true,concat_pred)\n","        return lossR + self.alpha * lossP\n","\n","    #compute loss\n","    def call(self, concat_true, concat_pred):\n","        return self.standard_loss(concat_true,concat_pred)"]},{"cell_type":"code","execution_count":7,"id":"81c8c560","metadata":{"id":"81c8c560","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":6,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["class TarReg_Loss(Base_Loss):\n","    #initialize instance attributes\n","    def __init__(self, alpha=1,beta=1):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.beta=beta\n","        self.name='tarreg_loss'\n","\n","    def split_pred(self,concat_pred):\n","        #generic helper to make sure we dont make mistakes\n","        preds={}\n","        preds['y0_pred'] = concat_pred[:, 0]\n","        preds['y1_pred'] = concat_pred[:, 1]\n","        preds['t_pred'] = concat_pred[:, 2]\n","        preds['epsilon'] = concat_pred[:, 3] #we're moving epsilon into slot three\n","        preds['phi'] = concat_pred[:, 4:]\n","        return preds\n","\n","    def calc_hstar(self,concat_true,concat_pred):\n","        #step 2 above\n","        p=self.split_pred(concat_pred)\n","        y_true = concat_true[:, 0]\n","        t_true = concat_true[:, 1]\n","\n","        t_pred = tf.math.sigmoid(concat_pred[:, 2])\n","        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n","        y_pred = t_true * p['y1_pred'] + (1 - t_true) * p['y0_pred']\n","\n","        #calling it cc for \"clever covariate\" as in SuperLearner TMLE literature\n","        cc = t_true / t_pred - (1 - t_true) / (1 - t_pred)\n","        h_star = y_pred + p['epsilon'] * cc\n","        return h_star\n","\n","    def call(self,concat_true,concat_pred):\n","        y_true = concat_true[:, 0]\n","\n","        standard_loss=self.standard_loss(concat_true,concat_pred)\n","        h_star=self.calc_hstar(concat_true,concat_pred)\n","        #step 3 above\n","        targeted_regularization = tf.reduce_sum(tf.square(y_true - h_star))\n","\n","        # final\n","        loss = standard_loss + self.beta * targeted_regularization\n","        return loss"]},{"cell_type":"code","execution_count":8,"id":"64d95324","metadata":{"id":"64d95324","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":6,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["\n","#https://towardsdatascience.com/implementing-macro-f1-score-in-keras-what-not-to-do-e9f1aa04029d\n","class Eval_metrics_train():\n","    def __init__(self,data):\n","        self.data=data #feed the callback the full dataset\n","        #needed for PEHEnn; Called in self.find_ynn\n","        self.data['o_idx']=tf.range(self.data['t'].shape[0])\n","        self.data['c_idx']=self.data['o_idx'][self.data['t'].squeeze()==0] #These are the indices of the control units\n","        self.data['t_idx']=self.data['o_idx'][self.data['t'].squeeze()==1] #These are the indices of the treated units\n","\n","    def split_pred(self,concat_pred):\n","        preds={}\n","        preds['y0_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n","        preds['y1_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n","        preds['t_pred'] = concat_pred[:, 2]\n","        preds['epsilon'] = concat_pred[:, 3]\n","        preds['phi'] = concat_pred[:, 4:]\n","        return preds\n","\n","    def ATE_absolute_error(self,concat_pred):\n","        p = self.split_pred(concat_pred)\n","        ATT_pred = tf.gather(params=self.data['y'], indices=self.data['t_idx']) - tf.gather(params=p['y0_pred'], indices=self.data['t_idx'])\n","        ATU_pred = tf.gather(params=p['y1_pred'], indices=self.data['c_idx']) - tf.gather(params=self.data['y'], indices=self.data['c_idx'])\n","        ATE_pred = tf.reduce_mean(tf.concat([ATT_pred,ATU_pred], axis=0)) #stitch em back up!\n","        ATE_actual = tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n","        return tf.abs(ATE_actual- ATE_pred)\n","\n","    def ITE_RMSE_error(self,concat_pred):\n","        #simulation only\n","        p = self.split_pred(concat_pred)\n","        y_1_treated_group = tf.gather(params=self.data['y'], indices=self.data['t_idx'])\n","        y_0_treated_group = tf.gather(params=p['y0_pred'], indices=self.data['t_idx'])\n","\n","        mu_1_treated_group = tf.gather(params=self.data['mu_1'], indices=self.data['t_idx'])\n","        mu_0_treated_group = tf.gather(params=self.data['mu_0'], indices=self.data['t_idx'])\n","\n","\n","        treat_grp_error = (y_1_treated_group - y_0_treated_group) - (mu_1_treated_group - mu_0_treated_group)\n","\n","        y_1_control_group = tf.gather(params=p['y1_pred'], indices=self.data['c_idx'])\n","        y_0_control_group = tf.gather(params=self.data['y'], indices=self.data['c_idx'])\n","\n","        mu_1_control_group = tf.gather(params=self.data['mu_1'], indices=self.data['c_idx'])\n","        mu_0_control_group = tf.gather(params=self.data['mu_0'], indices=self.data['c_idx'])\n","\n","        control_grp_error = (y_1_control_group - y_0_control_group) - (mu_1_control_group - mu_0_control_group)\n","\n","\n","        ITE_error = tf.concat([treat_grp_error, control_grp_error], axis=0)\n","        ITE_RMSE_error = tf.sqrt(tf.reduce_mean(tf.square(ITE_error)))\n","        return ITE_RMSE_error\n","\n","    def compute_hstar(self,y0_pred,y1_pred,t_pred,t_true,epsilons):\n","        #helper for calculating the targeted regularization cate\n","        y_pred = t_true * y1_pred + (1 - t_true) * y0_pred\n","        cc = t_true / t_pred - (1 - t_true) / (1 - t_pred)\n","        h_star = y_pred + epsilons * cc\n","        return h_star\n","\n","    def TARREG_ATE_absolute_error(self,concat_pred):\n","        #Final calculation of Targeted Regularization loss\n","        p = self.split_pred(concat_pred)\n","        t_pred = tf.math.sigmoid(p['t_pred'])\n","        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n","        hstar_0=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.zeros_like(p['epsilon']),p['epsilon'])\n","        hstar_1=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.ones_like(p['epsilon']),p['epsilon'])\n","        ate_true=tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n","        ate_tarreg_pred = tf.reduce_mean(hstar_1-hstar_0)\n","        return tf.abs(ate_true- ate_tarreg_pred)"]},{"cell_type":"code","execution_count":9,"id":"a4b86afe","metadata":{"id":"a4b86afe","executionInfo":{"status":"ok","timestamp":1725482441872,"user_tz":240,"elapsed":5,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["\n","#https://towardsdatascience.com/implementing-macro-f1-score-in-keras-what-not-to-do-e9f1aa04029d\n","class Eval_metrics_test():\n","    def __init__(self,data):\n","        self.data=data #feed the callback the full dataset\n","\n","    def split_pred(self,concat_pred):\n","        preds={}\n","        preds['y0_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n","        preds['y1_pred'] = self.data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n","        preds['t_pred'] = concat_pred[:, 2]\n","        preds['epsilon'] = concat_pred[:, 3]\n","        preds['phi'] = concat_pred[:, 4:]\n","        return preds\n","\n","\n","    def PEHE(self,concat_pred):\n","        #simulation only\n","        p = self.split_pred(concat_pred)\n","        cate_err=tf.reduce_mean( tf.square( ( (self.data['mu_1']-self.data['mu_0']) - (p['y1_pred']-p['y0_pred']) ) ) )\n","        return tf.sqrt(cate_err)\n","\n","    def PEHE_tareg(self,concat_pred):\n","        #simulation only\n","        p = self.split_pred(concat_pred)\n","        t_pred = tf.math.sigmoid(p['t_pred'])\n","        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n","        hstar_0=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.zeros_like(p['epsilon']),p['epsilon'])\n","        hstar_1=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.ones_like(p['epsilon']),p['epsilon'])\n","\n","        cate_err=tf.reduce_mean( tf.square( ( (self.data['mu_1']-self.data['mu_0']) - (hstar_1-hstar_0) ) ) )\n","        return tf.sqrt(cate_err)\n","\n","\n","    def compute_hstar(self,y0_pred,y1_pred,t_pred,t_true,epsilons):\n","        #helper for calculating the targeted regularization cate\n","        y_pred = t_true * y1_pred + (1 - t_true) * y0_pred\n","        cc = t_true / t_pred - (1 - t_true) / (1 - t_pred)\n","        h_star = y_pred + epsilons * cc\n","        return h_star\n","\n","    def TARREG_ATE_absolute_error(self,concat_pred):\n","        #Final calculation of Targeted Regularization loss\n","        p = self.split_pred(concat_pred)\n","        t_pred = tf.math.sigmoid(p['t_pred'])\n","        t_pred = (t_pred + 0.001) / 1.002 # a little numerical stability trick implemented by Shi\n","        hstar_0=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.zeros_like(p['epsilon']),p['epsilon'])\n","        hstar_1=self.compute_hstar(p['y0_pred'],p['y1_pred'],t_pred,tf.ones_like(p['epsilon']),p['epsilon'])\n","        ate_true=tf.reduce_mean(self.data['mu_1']-self.data['mu_0'])\n","        print(tf.shape(hstar_1-hstar_0))\n","        ate_tarreg_pred = tf.reduce_mean(hstar_1-hstar_0)\n","        return tf.abs(ate_true- ate_tarreg_pred)"]},{"cell_type":"code","execution_count":19,"id":"48437e2b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48437e2b","executionInfo":{"status":"ok","timestamp":1725484236616,"user_tz":240,"elapsed":632606,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}},"outputId":"84743f69-61b6-4c61-ea17-60c20c122f7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["10\n","/content/drive/MyDrive/Causal_network_matching/data/BlogCatalog2/BlogCatalog9.mat\n","[[0. 1. 1. ... 0. 0. 0.]\n"," [1. 1. 1. ... 0. 0. 0.]\n"," [2. 1. 1. ... 0. 0. 0.]\n"," ...\n"," [4. 1. 1. ... 0. 0. 0.]\n"," [2. 2. 1. ... 0. 0. 0.]\n"," [1. 1. 1. ... 0. 0. 0.]]\n","Epoch 1/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 7600.6553 - regression_loss: 3543.3206 - tarreg_loss: 7595.9492 - treatment_acc: 0.5105 - val_loss: 2312.2354 - val_regression_loss: 1156.2117 - val_tarreg_loss: 2307.5293 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 2/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 6997.5508 - regression_loss: 3516.7434 - tarreg_loss: 6992.8447 - treatment_acc: 0.5096 - val_loss: 2298.6694 - val_regression_loss: 1151.9342 - val_tarreg_loss: 2293.9634 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 3/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 7032.2393 - regression_loss: 3483.0771 - tarreg_loss: 7027.5337 - treatment_acc: 0.5090 - val_loss: 2289.5571 - val_regression_loss: 1146.7714 - val_tarreg_loss: 2284.8511 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 4/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 6909.4146 - regression_loss: 3446.0278 - tarreg_loss: 6904.7085 - treatment_acc: 0.5084 - val_loss: 2280.4927 - val_regression_loss: 1140.9009 - val_tarreg_loss: 2275.7866 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 5/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 6779.7290 - regression_loss: 3407.9429 - tarreg_loss: 6775.0234 - treatment_acc: 0.5090 - val_loss: 2269.5752 - val_regression_loss: 1134.4281 - val_tarreg_loss: 2264.8691 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 6/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 6694.6367 - regression_loss: 3370.7202 - tarreg_loss: 6689.9307 - treatment_acc: 0.5081 - val_loss: 2256.7070 - val_regression_loss: 1127.5410 - val_tarreg_loss: 2252.0010 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 7/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 6626.0605 - regression_loss: 3335.3494 - tarreg_loss: 6621.3550 - treatment_acc: 0.5075 - val_loss: 2242.3293 - val_regression_loss: 1120.3044 - val_tarreg_loss: 2237.6233 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 8/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 6558.9932 - regression_loss: 3301.5000 - tarreg_loss: 6554.2871 - treatment_acc: 0.5078 - val_loss: 2227.6348 - val_regression_loss: 1113.0748 - val_tarreg_loss: 2222.9287 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 9/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 6494.7534 - regression_loss: 3269.5093 - tarreg_loss: 6490.0479 - treatment_acc: 0.5084 - val_loss: 2212.8762 - val_regression_loss: 1105.8057 - val_tarreg_loss: 2208.1702 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 10/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 6433.7339 - regression_loss: 3238.5703 - tarreg_loss: 6429.0283 - treatment_acc: 0.5081 - val_loss: 2198.6021 - val_regression_loss: 1098.6934 - val_tarreg_loss: 2193.8960 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 11/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 6375.9434 - regression_loss: 3208.7051 - tarreg_loss: 6371.2378 - treatment_acc: 0.5072 - val_loss: 2184.8806 - val_regression_loss: 1091.7632 - val_tarreg_loss: 2180.1746 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 12/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 6319.9517 - regression_loss: 3179.5881 - tarreg_loss: 6315.2461 - treatment_acc: 0.5069 - val_loss: 2171.9287 - val_regression_loss: 1085.1510 - val_tarreg_loss: 2167.2227 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 13/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 6265.7944 - regression_loss: 3151.3796 - tarreg_loss: 6261.0889 - treatment_acc: 0.5078 - val_loss: 2159.7041 - val_regression_loss: 1078.8710 - val_tarreg_loss: 2154.9980 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 14/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 6213.0464 - regression_loss: 3123.8386 - tarreg_loss: 6208.3408 - treatment_acc: 0.5084 - val_loss: 2148.3503 - val_regression_loss: 1073.0215 - val_tarreg_loss: 2143.6445 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 15/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 6163.0200 - regression_loss: 3097.6450 - tarreg_loss: 6158.3145 - treatment_acc: 0.5087 - val_loss: 2137.7041 - val_regression_loss: 1067.5364 - val_tarreg_loss: 2132.9985 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 16/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 6116.0864 - regression_loss: 3072.9375 - tarreg_loss: 6111.3809 - treatment_acc: 0.5087 - val_loss: 2127.8552 - val_regression_loss: 1062.4669 - val_tarreg_loss: 2123.1499 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 17/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 6072.5146 - regression_loss: 3049.9312 - tarreg_loss: 6067.8086 - treatment_acc: 0.5087 - val_loss: 2118.7737 - val_regression_loss: 1057.7974 - val_tarreg_loss: 2114.0684 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 18/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 6032.2168 - regression_loss: 3028.5439 - tarreg_loss: 6027.5112 - treatment_acc: 0.5096 - val_loss: 2110.5251 - val_regression_loss: 1053.5583 - val_tarreg_loss: 2105.8198 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 19/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5995.9575 - regression_loss: 3009.2573 - tarreg_loss: 5991.2520 - treatment_acc: 0.5099 - val_loss: 2102.9753 - val_regression_loss: 1049.6775 - val_tarreg_loss: 2098.2700 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 20/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 5962.9292 - regression_loss: 2991.5767 - tarreg_loss: 5958.2236 - treatment_acc: 0.5102 - val_loss: 2096.0652 - val_regression_loss: 1046.1243 - val_tarreg_loss: 2091.3599 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 21/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5933.0449 - regression_loss: 2975.5754 - tarreg_loss: 5928.3398 - treatment_acc: 0.5105 - val_loss: 2089.8855 - val_regression_loss: 1042.9445 - val_tarreg_loss: 2085.1802 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 22/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5905.7622 - regression_loss: 2960.9241 - tarreg_loss: 5901.0566 - treatment_acc: 0.5099 - val_loss: 2084.2029 - val_regression_loss: 1040.0197 - val_tarreg_loss: 2079.4976 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 23/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5880.5420 - regression_loss: 2947.3687 - tarreg_loss: 5875.8364 - treatment_acc: 0.5093 - val_loss: 2079.0349 - val_regression_loss: 1037.3590 - val_tarreg_loss: 2074.3296 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 24/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5857.4346 - regression_loss: 2934.9790 - tarreg_loss: 5852.7290 - treatment_acc: 0.5096 - val_loss: 2074.2666 - val_regression_loss: 1034.9061 - val_tarreg_loss: 2069.5615 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 25/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5835.6777 - regression_loss: 2923.3223 - tarreg_loss: 5830.9717 - treatment_acc: 0.5093 - val_loss: 2069.8918 - val_regression_loss: 1032.6584 - val_tarreg_loss: 2065.1870 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 26/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5815.2563 - regression_loss: 2912.4031 - tarreg_loss: 5810.5508 - treatment_acc: 0.5087 - val_loss: 2065.7549 - val_regression_loss: 1030.5370 - val_tarreg_loss: 2061.0503 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 27/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5796.1875 - regression_loss: 2902.2502 - tarreg_loss: 5791.4824 - treatment_acc: 0.5090 - val_loss: 2061.9836 - val_regression_loss: 1028.6058 - val_tarreg_loss: 2057.2791 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 28/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 5778.0527 - regression_loss: 2892.6211 - tarreg_loss: 5773.3477 - treatment_acc: 0.5087 - val_loss: 2058.3967 - val_regression_loss: 1026.7731 - val_tarreg_loss: 2053.6921 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 29/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5760.7461 - regression_loss: 2883.4463 - tarreg_loss: 5756.0405 - treatment_acc: 0.5087 - val_loss: 2054.9746 - val_regression_loss: 1025.0289 - val_tarreg_loss: 2050.2700 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 30/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 5744.2334 - regression_loss: 2874.7354 - tarreg_loss: 5739.5283 - treatment_acc: 0.5087 - val_loss: 2051.7839 - val_regression_loss: 1023.4053 - val_tarreg_loss: 2047.0793 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 31/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5728.4775 - regression_loss: 2866.4829 - tarreg_loss: 5723.7725 - treatment_acc: 0.5084 - val_loss: 2048.6221 - val_regression_loss: 1021.8005 - val_tarreg_loss: 2043.9174 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 32/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5713.3442 - regression_loss: 2858.5608 - tarreg_loss: 5708.6392 - treatment_acc: 0.5087 - val_loss: 2045.5994 - val_regression_loss: 1020.2691 - val_tarreg_loss: 2040.8945 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 33/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5698.6738 - regression_loss: 2850.9126 - tarreg_loss: 5693.9688 - treatment_acc: 0.5087 - val_loss: 2042.7012 - val_regression_loss: 1018.8029 - val_tarreg_loss: 2037.9963 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 34/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5684.4922 - regression_loss: 2843.5464 - tarreg_loss: 5679.7871 - treatment_acc: 0.5087 - val_loss: 2039.8058 - val_regression_loss: 1017.3411 - val_tarreg_loss: 2035.1011 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 35/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5670.4668 - regression_loss: 2836.2869 - tarreg_loss: 5665.7617 - treatment_acc: 0.5084 - val_loss: 2037.0256 - val_regression_loss: 1015.9395 - val_tarreg_loss: 2032.3212 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 36/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5656.9775 - regression_loss: 2829.3574 - tarreg_loss: 5652.2729 - treatment_acc: 0.5081 - val_loss: 2034.2908 - val_regression_loss: 1014.5624 - val_tarreg_loss: 2029.5862 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 37/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5643.5215 - regression_loss: 2822.4453 - tarreg_loss: 5638.8169 - treatment_acc: 0.5084 - val_loss: 2031.5970 - val_regression_loss: 1013.2081 - val_tarreg_loss: 2026.8926 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 38/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5630.3218 - regression_loss: 2815.6897 - tarreg_loss: 5625.6172 - treatment_acc: 0.5078 - val_loss: 2028.9813 - val_regression_loss: 1011.8942 - val_tarreg_loss: 2024.2769 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 39/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5617.1680 - regression_loss: 2808.9746 - tarreg_loss: 5612.4634 - treatment_acc: 0.5075 - val_loss: 2026.4272 - val_regression_loss: 1010.6121 - val_tarreg_loss: 2021.7228 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 40/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5604.2974 - regression_loss: 2802.4163 - tarreg_loss: 5599.5928 - treatment_acc: 0.5075 - val_loss: 2023.8672 - val_regression_loss: 1009.3286 - val_tarreg_loss: 2019.1627 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 41/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5591.4526 - regression_loss: 2795.8845 - tarreg_loss: 5586.7480 - treatment_acc: 0.5078 - val_loss: 2021.3947 - val_regression_loss: 1008.0897 - val_tarreg_loss: 2016.6902 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 42/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5579.0347 - regression_loss: 2789.5847 - tarreg_loss: 5574.3301 - treatment_acc: 0.5078 - val_loss: 2018.9191 - val_regression_loss: 1006.8503 - val_tarreg_loss: 2014.2146 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 43/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 5566.5864 - regression_loss: 2783.2769 - tarreg_loss: 5561.8828 - treatment_acc: 0.5075 - val_loss: 2016.4955 - val_regression_loss: 1005.6373 - val_tarreg_loss: 2011.7910 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 44/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5554.4512 - regression_loss: 2777.1494 - tarreg_loss: 5549.7471 - treatment_acc: 0.5075 - val_loss: 2014.1417 - val_regression_loss: 1004.4601 - val_tarreg_loss: 2009.4373 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 45/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5542.4136 - regression_loss: 2771.0554 - tarreg_loss: 5537.7095 - treatment_acc: 0.5072 - val_loss: 2011.8145 - val_regression_loss: 1003.2966 - val_tarreg_loss: 2007.1101 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 46/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5530.7095 - regression_loss: 2765.1492 - tarreg_loss: 5526.0054 - treatment_acc: 0.5075 - val_loss: 2009.5571 - val_regression_loss: 1002.1683 - val_tarreg_loss: 2004.8528 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 47/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5519.0898 - regression_loss: 2759.2900 - tarreg_loss: 5514.3857 - treatment_acc: 0.5072 - val_loss: 2007.3367 - val_regression_loss: 1001.0589 - val_tarreg_loss: 2002.6323 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 48/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5507.7549 - regression_loss: 2753.5706 - tarreg_loss: 5503.0508 - treatment_acc: 0.5072 - val_loss: 2005.2065 - val_regression_loss: 999.9949 - val_tarreg_loss: 2000.5024 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 49/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5496.6323 - regression_loss: 2747.9612 - tarreg_loss: 5491.9282 - treatment_acc: 0.5072 - val_loss: 2002.9705 - val_regression_loss: 998.8779 - val_tarreg_loss: 1998.2662 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 50/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5485.5850 - regression_loss: 2742.3936 - tarreg_loss: 5480.8809 - treatment_acc: 0.5069 - val_loss: 2000.8983 - val_regression_loss: 997.8433 - val_tarreg_loss: 1996.1943 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 51/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5474.9238 - regression_loss: 2737.0220 - tarreg_loss: 5470.2202 - treatment_acc: 0.5075 - val_loss: 1998.8107 - val_regression_loss: 996.8007 - val_tarreg_loss: 1994.1067 - val_treatment_acc: 0.5156 - learning_rate: 6.0000e-08\n","Epoch 52/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5464.2910 - regression_loss: 2731.6675 - tarreg_loss: 5459.5879 - treatment_acc: 0.5075 - val_loss: 1996.8507 - val_regression_loss: 995.8219 - val_tarreg_loss: 1992.1466 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 53/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5453.8970 - regression_loss: 2726.4358 - tarreg_loss: 5449.1934 - treatment_acc: 0.5075 - val_loss: 1994.8944 - val_regression_loss: 994.8452 - val_tarreg_loss: 1990.1904 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 54/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5443.7690 - regression_loss: 2721.3328 - tarreg_loss: 5439.0654 - treatment_acc: 0.5072 - val_loss: 1993.0447 - val_regression_loss: 993.9215 - val_tarreg_loss: 1988.3407 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 55/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5433.8154 - regression_loss: 2716.3188 - tarreg_loss: 5429.1118 - treatment_acc: 0.5072 - val_loss: 1991.0642 - val_regression_loss: 992.9324 - val_tarreg_loss: 1986.3602 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 56/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 5423.8931 - regression_loss: 2711.3252 - tarreg_loss: 5419.1895 - treatment_acc: 0.5069 - val_loss: 1989.2316 - val_regression_loss: 992.0172 - val_tarreg_loss: 1984.5277 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 57/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5414.1509 - regression_loss: 2706.4124 - tarreg_loss: 5409.4473 - treatment_acc: 0.5072 - val_loss: 1987.4393 - val_regression_loss: 991.1221 - val_tarreg_loss: 1982.7355 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 58/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 5404.6943 - regression_loss: 2701.6504 - tarreg_loss: 5399.9907 - treatment_acc: 0.5069 - val_loss: 1985.6980 - val_regression_loss: 990.2521 - val_tarreg_loss: 1980.9941 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 59/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5395.4102 - regression_loss: 2696.9731 - tarreg_loss: 5390.7070 - treatment_acc: 0.5072 - val_loss: 1983.9202 - val_regression_loss: 989.3638 - val_tarreg_loss: 1979.2163 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 60/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5386.0493 - regression_loss: 2692.2539 - tarreg_loss: 5381.3457 - treatment_acc: 0.5072 - val_loss: 1982.2566 - val_regression_loss: 988.5327 - val_tarreg_loss: 1977.5527 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 61/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5377.0669 - regression_loss: 2687.7351 - tarreg_loss: 5372.3633 - treatment_acc: 0.5072 - val_loss: 1980.6119 - val_regression_loss: 987.7109 - val_tarreg_loss: 1975.9082 - val_treatment_acc: 0.5168 - learning_rate: 6.0000e-08\n","Epoch 62/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5368.1714 - regression_loss: 2683.2466 - tarreg_loss: 5363.4678 - treatment_acc: 0.5075 - val_loss: 1978.9863 - val_regression_loss: 986.8981 - val_tarreg_loss: 1974.2827 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 63/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5359.4580 - regression_loss: 2678.8552 - tarreg_loss: 5354.7544 - treatment_acc: 0.5075 - val_loss: 1977.4080 - val_regression_loss: 986.1091 - val_tarreg_loss: 1972.7043 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 64/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5350.7720 - regression_loss: 2674.4709 - tarreg_loss: 5346.0684 - treatment_acc: 0.5075 - val_loss: 1975.7700 - val_regression_loss: 985.2898 - val_tarreg_loss: 1971.0664 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 65/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5342.2642 - regression_loss: 2670.1812 - tarreg_loss: 5337.5605 - treatment_acc: 0.5075 - val_loss: 1974.2491 - val_regression_loss: 984.5288 - val_tarreg_loss: 1969.5454 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 66/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5333.9634 - regression_loss: 2665.9993 - tarreg_loss: 5329.2598 - treatment_acc: 0.5075 - val_loss: 1972.7146 - val_regression_loss: 983.7612 - val_tarreg_loss: 1968.0111 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 67/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5325.7236 - regression_loss: 2661.8450 - tarreg_loss: 5321.0205 - treatment_acc: 0.5078 - val_loss: 1971.1654 - val_regression_loss: 982.9862 - val_tarreg_loss: 1966.4619 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 68/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5317.4087 - regression_loss: 2657.6426 - tarreg_loss: 5312.7051 - treatment_acc: 0.5081 - val_loss: 1969.7493 - val_regression_loss: 982.2773 - val_tarreg_loss: 1965.0458 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 69/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5309.4775 - regression_loss: 2653.6450 - tarreg_loss: 5304.7744 - treatment_acc: 0.5078 - val_loss: 1968.3221 - val_regression_loss: 981.5629 - val_tarreg_loss: 1963.6187 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 70/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5301.5669 - regression_loss: 2649.6577 - tarreg_loss: 5296.8633 - treatment_acc: 0.5078 - val_loss: 1966.8823 - val_regression_loss: 980.8423 - val_tarreg_loss: 1962.1790 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 71/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5293.7290 - regression_loss: 2645.7031 - tarreg_loss: 5289.0254 - treatment_acc: 0.5078 - val_loss: 1965.4764 - val_regression_loss: 980.1382 - val_tarreg_loss: 1960.7731 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 72/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 5286.0107 - regression_loss: 2641.8110 - tarreg_loss: 5281.3076 - treatment_acc: 0.5078 - val_loss: 1964.0935 - val_regression_loss: 979.4456 - val_tarreg_loss: 1959.3901 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 73/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 5278.2871 - regression_loss: 2637.9194 - tarreg_loss: 5273.5840 - treatment_acc: 0.5078 - val_loss: 1962.7473 - val_regression_loss: 978.7711 - val_tarreg_loss: 1958.0439 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 74/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5270.8213 - regression_loss: 2634.1541 - tarreg_loss: 5266.1182 - treatment_acc: 0.5078 - val_loss: 1961.4036 - val_regression_loss: 978.0983 - val_tarreg_loss: 1956.7002 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 75/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 5263.4629 - regression_loss: 2630.4470 - tarreg_loss: 5258.7598 - treatment_acc: 0.5078 - val_loss: 1960.0917 - val_regression_loss: 977.4412 - val_tarreg_loss: 1955.3883 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 76/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5256.0859 - regression_loss: 2626.7224 - tarreg_loss: 5251.3828 - treatment_acc: 0.5075 - val_loss: 1958.8055 - val_regression_loss: 976.7968 - val_tarreg_loss: 1954.1023 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 77/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 5248.8843 - regression_loss: 2623.0918 - tarreg_loss: 5244.1816 - treatment_acc: 0.5075 - val_loss: 1957.5642 - val_regression_loss: 976.1746 - val_tarreg_loss: 1952.8608 - val_treatment_acc: 0.5180 - learning_rate: 6.0000e-08\n","Epoch 78/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5241.7314 - regression_loss: 2619.4875 - tarreg_loss: 5237.0288 - treatment_acc: 0.5072 - val_loss: 1956.2773 - val_regression_loss: 975.5295 - val_tarreg_loss: 1951.5740 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 79/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 5234.6685 - regression_loss: 2615.9224 - tarreg_loss: 5229.9653 - treatment_acc: 0.5072 - val_loss: 1955.0344 - val_regression_loss: 974.9065 - val_tarreg_loss: 1950.3311 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 80/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5227.6133 - regression_loss: 2612.3655 - tarreg_loss: 5222.9102 - treatment_acc: 0.5072 - val_loss: 1953.7954 - val_regression_loss: 974.2853 - val_tarreg_loss: 1949.0920 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 81/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 5220.7866 - regression_loss: 2608.9285 - tarreg_loss: 5216.0830 - treatment_acc: 0.5072 - val_loss: 1952.5851 - val_regression_loss: 973.6788 - val_tarreg_loss: 1947.8818 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 82/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 5213.9927 - regression_loss: 2605.5061 - tarreg_loss: 5209.2896 - treatment_acc: 0.5075 - val_loss: 1951.3689 - val_regression_loss: 973.0693 - val_tarreg_loss: 1946.6658 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 83/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5207.1274 - regression_loss: 2602.0464 - tarreg_loss: 5202.4243 - treatment_acc: 0.5075 - val_loss: 1950.2009 - val_regression_loss: 972.4839 - val_tarreg_loss: 1945.4977 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 84/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5200.3843 - regression_loss: 2598.6453 - tarreg_loss: 5195.6812 - treatment_acc: 0.5075 - val_loss: 1949.0168 - val_regression_loss: 971.8906 - val_tarreg_loss: 1944.3137 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 85/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5193.8022 - regression_loss: 2595.3315 - tarreg_loss: 5189.0986 - treatment_acc: 0.5072 - val_loss: 1947.8748 - val_regression_loss: 971.3178 - val_tarreg_loss: 1943.1716 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 86/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5187.3091 - regression_loss: 2592.0632 - tarreg_loss: 5182.6060 - treatment_acc: 0.5072 - val_loss: 1946.8197 - val_regression_loss: 970.7888 - val_tarreg_loss: 1942.1167 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 87/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5180.8760 - regression_loss: 2588.8245 - tarreg_loss: 5176.1729 - treatment_acc: 0.5072 - val_loss: 1945.6512 - val_regression_loss: 970.2031 - val_tarreg_loss: 1940.9482 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 88/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5174.4941 - regression_loss: 2585.6040 - tarreg_loss: 5169.7910 - treatment_acc: 0.5072 - val_loss: 1944.5575 - val_regression_loss: 969.6547 - val_tarreg_loss: 1939.8545 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 89/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5168.1719 - regression_loss: 2582.4158 - tarreg_loss: 5163.4692 - treatment_acc: 0.5072 - val_loss: 1943.4550 - val_regression_loss: 969.1019 - val_tarreg_loss: 1938.7520 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 90/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5161.9551 - regression_loss: 2579.2869 - tarreg_loss: 5157.2520 - treatment_acc: 0.5072 - val_loss: 1942.4115 - val_regression_loss: 968.5786 - val_tarreg_loss: 1937.7085 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 91/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5155.7598 - regression_loss: 2576.1699 - tarreg_loss: 5151.0566 - treatment_acc: 0.5072 - val_loss: 1941.3807 - val_regression_loss: 968.0618 - val_tarreg_loss: 1936.6777 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 92/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5149.6562 - regression_loss: 2573.1003 - tarreg_loss: 5144.9531 - treatment_acc: 0.5075 - val_loss: 1940.2830 - val_regression_loss: 967.5114 - val_tarreg_loss: 1935.5798 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 93/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 5143.4556 - regression_loss: 2569.9766 - tarreg_loss: 5138.7529 - treatment_acc: 0.5069 - val_loss: 1939.2260 - val_regression_loss: 966.9815 - val_tarreg_loss: 1934.5229 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 94/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 5137.5366 - regression_loss: 2566.9980 - tarreg_loss: 5132.8340 - treatment_acc: 0.5066 - val_loss: 1938.2118 - val_regression_loss: 966.4731 - val_tarreg_loss: 1933.5089 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 95/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5131.6011 - regression_loss: 2564.0081 - tarreg_loss: 5126.8984 - treatment_acc: 0.5069 - val_loss: 1937.2572 - val_regression_loss: 965.9943 - val_tarreg_loss: 1932.5542 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 96/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5125.6807 - regression_loss: 2561.0212 - tarreg_loss: 5120.9780 - treatment_acc: 0.5069 - val_loss: 1936.2085 - val_regression_loss: 965.4684 - val_tarreg_loss: 1931.5056 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 97/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5119.9019 - regression_loss: 2558.1128 - tarreg_loss: 5115.1992 - treatment_acc: 0.5069 - val_loss: 1935.1980 - val_regression_loss: 964.9616 - val_tarreg_loss: 1930.4951 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 98/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5114.0654 - regression_loss: 2555.1746 - tarreg_loss: 5109.3628 - treatment_acc: 0.5069 - val_loss: 1934.2179 - val_regression_loss: 964.4700 - val_tarreg_loss: 1929.5149 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 99/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 5108.3608 - regression_loss: 2552.3047 - tarreg_loss: 5103.6582 - treatment_acc: 0.5072 - val_loss: 1933.2791 - val_regression_loss: 963.9993 - val_tarreg_loss: 1928.5762 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 100/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 5102.7661 - regression_loss: 2549.4905 - tarreg_loss: 5098.0635 - treatment_acc: 0.5069 - val_loss: 1932.3142 - val_regression_loss: 963.5155 - val_tarreg_loss: 1927.6112 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 101/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 5097.1274 - regression_loss: 2546.6504 - tarreg_loss: 5092.4248 - treatment_acc: 0.5069 - val_loss: 1931.3726 - val_regression_loss: 963.0435 - val_tarreg_loss: 1926.6697 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 102/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 5091.5630 - regression_loss: 2543.8489 - tarreg_loss: 5086.8604 - treatment_acc: 0.5069 - val_loss: 1930.4142 - val_regression_loss: 962.5629 - val_tarreg_loss: 1925.7113 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 103/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 5086.0146 - regression_loss: 2541.0591 - tarreg_loss: 5081.3115 - treatment_acc: 0.5069 - val_loss: 1929.5260 - val_regression_loss: 962.1175 - val_tarreg_loss: 1924.8231 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 104/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5080.5845 - regression_loss: 2538.3259 - tarreg_loss: 5075.8818 - treatment_acc: 0.5063 - val_loss: 1928.5809 - val_regression_loss: 961.6439 - val_tarreg_loss: 1923.8782 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 105/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 5075.2627 - regression_loss: 2535.6514 - tarreg_loss: 5070.5605 - treatment_acc: 0.5066 - val_loss: 1927.7023 - val_regression_loss: 961.2034 - val_tarreg_loss: 1922.9995 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 106/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5069.9258 - regression_loss: 2532.9688 - tarreg_loss: 5065.2236 - treatment_acc: 0.5069 - val_loss: 1926.8225 - val_regression_loss: 960.7626 - val_tarreg_loss: 1922.1199 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 107/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5064.5269 - regression_loss: 2530.2534 - tarreg_loss: 5059.8242 - treatment_acc: 0.5069 - val_loss: 1925.9155 - val_regression_loss: 960.3081 - val_tarreg_loss: 1921.2128 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 108/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 5059.2573 - regression_loss: 2527.6052 - tarreg_loss: 5054.5547 - treatment_acc: 0.5069 - val_loss: 1925.0721 - val_regression_loss: 959.8854 - val_tarreg_loss: 1920.3695 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 109/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5054.1069 - regression_loss: 2525.0171 - tarreg_loss: 5049.4043 - treatment_acc: 0.5069 - val_loss: 1924.2048 - val_regression_loss: 959.4508 - val_tarreg_loss: 1919.5022 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 110/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 5048.9048 - regression_loss: 2522.4038 - tarreg_loss: 5044.2021 - treatment_acc: 0.5069 - val_loss: 1923.3458 - val_regression_loss: 959.0203 - val_tarreg_loss: 1918.6433 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 111/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 5043.8022 - regression_loss: 2519.8328 - tarreg_loss: 5039.0996 - treatment_acc: 0.5069 - val_loss: 1922.5243 - val_regression_loss: 958.6086 - val_tarreg_loss: 1917.8218 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 112/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 5038.7202 - regression_loss: 2517.2795 - tarreg_loss: 5034.0176 - treatment_acc: 0.5069 - val_loss: 1921.6823 - val_regression_loss: 958.1866 - val_tarreg_loss: 1916.9797 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 113/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5033.6108 - regression_loss: 2514.7090 - tarreg_loss: 5028.9082 - treatment_acc: 0.5075 - val_loss: 1920.8124 - val_regression_loss: 957.7504 - val_tarreg_loss: 1916.1099 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 114/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5028.6416 - regression_loss: 2512.2092 - tarreg_loss: 5023.9390 - treatment_acc: 0.5075 - val_loss: 1920.0018 - val_regression_loss: 957.3441 - val_tarreg_loss: 1915.2993 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 115/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 5023.6909 - regression_loss: 2509.7217 - tarreg_loss: 5018.9883 - treatment_acc: 0.5075 - val_loss: 1919.2249 - val_regression_loss: 956.9547 - val_tarreg_loss: 1914.5225 - val_treatment_acc: 0.5192 - learning_rate: 6.0000e-08\n","Epoch 116/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 5018.7476 - regression_loss: 2507.2402 - tarreg_loss: 5014.0449 - treatment_acc: 0.5078 - val_loss: 1918.3982 - val_regression_loss: 956.5402 - val_tarreg_loss: 1913.6956 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 117/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 5013.9238 - regression_loss: 2504.8142 - tarreg_loss: 5009.2212 - treatment_acc: 0.5078 - val_loss: 1917.6454 - val_regression_loss: 956.1630 - val_tarreg_loss: 1912.9429 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 118/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 5009.1709 - regression_loss: 2502.4265 - tarreg_loss: 5004.4683 - treatment_acc: 0.5078 - val_loss: 1916.8790 - val_regression_loss: 955.7791 - val_tarreg_loss: 1912.1765 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 119/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 5004.3804 - regression_loss: 2500.0225 - tarreg_loss: 4999.6777 - treatment_acc: 0.5081 - val_loss: 1916.0536 - val_regression_loss: 955.3655 - val_tarreg_loss: 1911.3511 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 120/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4999.5635 - regression_loss: 2497.6013 - tarreg_loss: 4994.8608 - treatment_acc: 0.5081 - val_loss: 1915.3315 - val_regression_loss: 955.0038 - val_tarreg_loss: 1910.6290 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 121/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4994.7642 - regression_loss: 2495.1895 - tarreg_loss: 4990.0615 - treatment_acc: 0.5081 - val_loss: 1914.5819 - val_regression_loss: 954.6282 - val_tarreg_loss: 1909.8794 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 122/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4990.1782 - regression_loss: 2492.8848 - tarreg_loss: 4985.4756 - treatment_acc: 0.5081 - val_loss: 1913.8435 - val_regression_loss: 954.2581 - val_tarreg_loss: 1909.1409 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 123/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4985.5669 - regression_loss: 2490.5713 - tarreg_loss: 4980.8643 - treatment_acc: 0.5081 - val_loss: 1913.1256 - val_regression_loss: 953.8984 - val_tarreg_loss: 1908.4231 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 124/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4980.8940 - regression_loss: 2488.2256 - tarreg_loss: 4976.1914 - treatment_acc: 0.5081 - val_loss: 1912.4003 - val_regression_loss: 953.5351 - val_tarreg_loss: 1907.6978 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 125/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4976.2251 - regression_loss: 2485.8818 - tarreg_loss: 4971.5225 - treatment_acc: 0.5081 - val_loss: 1911.6506 - val_regression_loss: 953.1595 - val_tarreg_loss: 1906.9482 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 126/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4971.8354 - regression_loss: 2483.6768 - tarreg_loss: 4967.1328 - treatment_acc: 0.5084 - val_loss: 1910.9445 - val_regression_loss: 952.8055 - val_tarreg_loss: 1906.2418 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 127/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4967.2319 - regression_loss: 2481.3647 - tarreg_loss: 4962.5293 - treatment_acc: 0.5084 - val_loss: 1910.2299 - val_regression_loss: 952.4478 - val_tarreg_loss: 1905.5273 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 128/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4962.7725 - regression_loss: 2479.1240 - tarreg_loss: 4958.0698 - treatment_acc: 0.5084 - val_loss: 1909.5276 - val_regression_loss: 952.0958 - val_tarreg_loss: 1904.8252 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 129/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4958.3413 - regression_loss: 2476.9016 - tarreg_loss: 4953.6387 - treatment_acc: 0.5084 - val_loss: 1908.8380 - val_regression_loss: 951.7502 - val_tarreg_loss: 1904.1355 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 130/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4954.0151 - regression_loss: 2474.7295 - tarreg_loss: 4949.3125 - treatment_acc: 0.5084 - val_loss: 1908.0977 - val_regression_loss: 951.3796 - val_tarreg_loss: 1903.3953 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 131/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4949.6318 - regression_loss: 2472.5320 - tarreg_loss: 4944.9292 - treatment_acc: 0.5084 - val_loss: 1907.4406 - val_regression_loss: 951.0504 - val_tarreg_loss: 1902.7382 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 132/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4945.2715 - regression_loss: 2470.3423 - tarreg_loss: 4940.5688 - treatment_acc: 0.5084 - val_loss: 1906.7626 - val_regression_loss: 950.7109 - val_tarreg_loss: 1902.0604 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 133/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4940.8730 - regression_loss: 2468.1348 - tarreg_loss: 4936.1704 - treatment_acc: 0.5084 - val_loss: 1906.0491 - val_regression_loss: 950.3535 - val_tarreg_loss: 1901.3468 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 134/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4936.6079 - regression_loss: 2465.9956 - tarreg_loss: 4931.9053 - treatment_acc: 0.5084 - val_loss: 1905.4642 - val_regression_loss: 950.0605 - val_tarreg_loss: 1900.7620 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 135/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4932.3408 - regression_loss: 2463.8501 - tarreg_loss: 4927.6382 - treatment_acc: 0.5084 - val_loss: 1904.7581 - val_regression_loss: 949.7067 - val_tarreg_loss: 1900.0559 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 136/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4928.1743 - regression_loss: 2461.7615 - tarreg_loss: 4923.4717 - treatment_acc: 0.5084 - val_loss: 1904.1603 - val_regression_loss: 949.4072 - val_tarreg_loss: 1899.4580 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 137/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4923.9478 - regression_loss: 2459.6416 - tarreg_loss: 4919.2451 - treatment_acc: 0.5084 - val_loss: 1903.5033 - val_regression_loss: 949.0781 - val_tarreg_loss: 1898.8010 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 138/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4919.7554 - regression_loss: 2457.5359 - tarreg_loss: 4915.0527 - treatment_acc: 0.5084 - val_loss: 1902.8651 - val_regression_loss: 948.7584 - val_tarreg_loss: 1898.1628 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 139/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4915.6138 - regression_loss: 2455.4583 - tarreg_loss: 4910.9111 - treatment_acc: 0.5084 - val_loss: 1902.2179 - val_regression_loss: 948.4341 - val_tarreg_loss: 1897.5156 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 140/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4911.5181 - regression_loss: 2453.4036 - tarreg_loss: 4906.8154 - treatment_acc: 0.5084 - val_loss: 1901.5892 - val_regression_loss: 948.1191 - val_tarreg_loss: 1896.8870 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 141/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4907.4272 - regression_loss: 2451.3535 - tarreg_loss: 4902.7246 - treatment_acc: 0.5084 - val_loss: 1900.9513 - val_regression_loss: 947.7997 - val_tarreg_loss: 1896.2491 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 142/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4903.3550 - regression_loss: 2449.3105 - tarreg_loss: 4898.6523 - treatment_acc: 0.5084 - val_loss: 1900.3762 - val_regression_loss: 947.5118 - val_tarreg_loss: 1895.6741 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 143/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4899.4121 - regression_loss: 2447.3333 - tarreg_loss: 4894.7095 - treatment_acc: 0.5081 - val_loss: 1899.7903 - val_regression_loss: 947.2184 - val_tarreg_loss: 1895.0881 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 144/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4895.3359 - regression_loss: 2445.2876 - tarreg_loss: 4890.6333 - treatment_acc: 0.5081 - val_loss: 1899.1956 - val_regression_loss: 946.9205 - val_tarreg_loss: 1894.4934 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 145/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4891.4468 - regression_loss: 2443.3369 - tarreg_loss: 4886.7441 - treatment_acc: 0.5084 - val_loss: 1898.5842 - val_regression_loss: 946.6144 - val_tarreg_loss: 1893.8821 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 146/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4887.3853 - regression_loss: 2441.2993 - tarreg_loss: 4882.6826 - treatment_acc: 0.5084 - val_loss: 1897.9861 - val_regression_loss: 946.3148 - val_tarreg_loss: 1893.2839 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 147/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4883.4819 - regression_loss: 2439.3418 - tarreg_loss: 4878.7793 - treatment_acc: 0.5084 - val_loss: 1897.3895 - val_regression_loss: 946.0160 - val_tarreg_loss: 1892.6874 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 148/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4879.6245 - regression_loss: 2437.4070 - tarreg_loss: 4874.9219 - treatment_acc: 0.5084 - val_loss: 1896.8602 - val_regression_loss: 945.7508 - val_tarreg_loss: 1892.1582 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 149/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4875.7681 - regression_loss: 2435.4727 - tarreg_loss: 4871.0654 - treatment_acc: 0.5087 - val_loss: 1896.3235 - val_regression_loss: 945.4818 - val_tarreg_loss: 1891.6213 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 150/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4871.8843 - regression_loss: 2433.5234 - tarreg_loss: 4867.1816 - treatment_acc: 0.5087 - val_loss: 1895.7749 - val_regression_loss: 945.2070 - val_tarreg_loss: 1891.0728 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 151/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4868.0918 - regression_loss: 2431.6221 - tarreg_loss: 4863.3896 - treatment_acc: 0.5087 - val_loss: 1895.1909 - val_regression_loss: 944.9145 - val_tarreg_loss: 1890.4888 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 152/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4864.2207 - regression_loss: 2429.6821 - tarreg_loss: 4859.5186 - treatment_acc: 0.5087 - val_loss: 1894.5890 - val_regression_loss: 944.6131 - val_tarreg_loss: 1889.8868 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 153/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4860.3350 - regression_loss: 2427.7329 - tarreg_loss: 4855.6328 - treatment_acc: 0.5087 - val_loss: 1894.0206 - val_regression_loss: 944.3284 - val_tarreg_loss: 1889.3185 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 154/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4856.6309 - regression_loss: 2425.8745 - tarreg_loss: 4851.9287 - treatment_acc: 0.5087 - val_loss: 1893.4928 - val_regression_loss: 944.0641 - val_tarreg_loss: 1888.7906 - val_treatment_acc: 0.5204 - learning_rate: 6.0000e-08\n","Epoch 155/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4852.7954 - regression_loss: 2423.9534 - tarreg_loss: 4848.0933 - treatment_acc: 0.5087 - val_loss: 1892.9880 - val_regression_loss: 943.8113 - val_tarreg_loss: 1888.2859 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 156/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4849.1416 - regression_loss: 2422.1206 - tarreg_loss: 4844.4395 - treatment_acc: 0.5087 - val_loss: 1892.4503 - val_regression_loss: 943.5421 - val_tarreg_loss: 1887.7482 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 157/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4845.4482 - regression_loss: 2420.2693 - tarreg_loss: 4840.7461 - treatment_acc: 0.5087 - val_loss: 1891.8943 - val_regression_loss: 943.2635 - val_tarreg_loss: 1887.1921 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 158/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4841.7656 - regression_loss: 2418.4231 - tarreg_loss: 4837.0635 - treatment_acc: 0.5084 - val_loss: 1891.3674 - val_regression_loss: 942.9998 - val_tarreg_loss: 1886.6654 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 159/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4838.1865 - regression_loss: 2416.6294 - tarreg_loss: 4833.4844 - treatment_acc: 0.5087 - val_loss: 1890.8518 - val_regression_loss: 942.7415 - val_tarreg_loss: 1886.1497 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 160/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4834.5518 - regression_loss: 2414.8066 - tarreg_loss: 4829.8496 - treatment_acc: 0.5087 - val_loss: 1890.3347 - val_regression_loss: 942.4825 - val_tarreg_loss: 1885.6326 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 161/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4830.8848 - regression_loss: 2412.9692 - tarreg_loss: 4826.1826 - treatment_acc: 0.5084 - val_loss: 1889.8112 - val_regression_loss: 942.2203 - val_tarreg_loss: 1885.1090 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 162/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4827.2700 - regression_loss: 2411.1565 - tarreg_loss: 4822.5679 - treatment_acc: 0.5084 - val_loss: 1889.3667 - val_regression_loss: 941.9976 - val_tarreg_loss: 1884.6646 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 163/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4823.6992 - regression_loss: 2409.3687 - tarreg_loss: 4818.9971 - treatment_acc: 0.5084 - val_loss: 1888.8937 - val_regression_loss: 941.7607 - val_tarreg_loss: 1884.1914 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 164/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4820.1279 - regression_loss: 2407.5786 - tarreg_loss: 4815.4258 - treatment_acc: 0.5084 - val_loss: 1888.4041 - val_regression_loss: 941.5156 - val_tarreg_loss: 1883.7019 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 165/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4816.5859 - regression_loss: 2405.8022 - tarreg_loss: 4811.8838 - treatment_acc: 0.5084 - val_loss: 1887.8601 - val_regression_loss: 941.2433 - val_tarreg_loss: 1883.1580 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 166/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 4813.0908 - regression_loss: 2404.0505 - tarreg_loss: 4808.3887 - treatment_acc: 0.5084 - val_loss: 1887.3853 - val_regression_loss: 941.0054 - val_tarreg_loss: 1882.6831 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 167/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4809.6602 - regression_loss: 2402.3311 - tarreg_loss: 4804.9580 - treatment_acc: 0.5084 - val_loss: 1886.9569 - val_regression_loss: 940.7910 - val_tarreg_loss: 1882.2549 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 168/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4806.1621 - regression_loss: 2400.5781 - tarreg_loss: 4801.4600 - treatment_acc: 0.5084 - val_loss: 1886.4427 - val_regression_loss: 940.5336 - val_tarreg_loss: 1881.7407 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 169/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4802.6914 - regression_loss: 2398.8401 - tarreg_loss: 4797.9893 - treatment_acc: 0.5084 - val_loss: 1885.9728 - val_regression_loss: 940.2982 - val_tarreg_loss: 1881.2706 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 170/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4799.2393 - regression_loss: 2397.1089 - tarreg_loss: 4794.5371 - treatment_acc: 0.5084 - val_loss: 1885.5054 - val_regression_loss: 940.0641 - val_tarreg_loss: 1880.8032 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 171/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4795.7441 - regression_loss: 2395.3584 - tarreg_loss: 4791.0420 - treatment_acc: 0.5084 - val_loss: 1885.0038 - val_regression_loss: 939.8129 - val_tarreg_loss: 1880.3015 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 172/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4792.3354 - regression_loss: 2393.6516 - tarreg_loss: 4787.6333 - treatment_acc: 0.5084 - val_loss: 1884.5729 - val_regression_loss: 939.5971 - val_tarreg_loss: 1879.8706 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 173/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4788.9570 - regression_loss: 2391.9587 - tarreg_loss: 4784.2549 - treatment_acc: 0.5084 - val_loss: 1884.1532 - val_regression_loss: 939.3871 - val_tarreg_loss: 1879.4512 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 174/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4785.6094 - regression_loss: 2390.2810 - tarreg_loss: 4780.9072 - treatment_acc: 0.5084 - val_loss: 1883.6848 - val_regression_loss: 939.1525 - val_tarreg_loss: 1878.9827 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 175/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4782.2539 - regression_loss: 2388.6021 - tarreg_loss: 4777.5518 - treatment_acc: 0.5084 - val_loss: 1883.2860 - val_regression_loss: 938.9530 - val_tarreg_loss: 1878.5840 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 176/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4778.9658 - regression_loss: 2386.9541 - tarreg_loss: 4774.2637 - treatment_acc: 0.5084 - val_loss: 1882.7964 - val_regression_loss: 938.7078 - val_tarreg_loss: 1878.0942 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 177/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4775.5513 - regression_loss: 2385.2429 - tarreg_loss: 4770.8491 - treatment_acc: 0.5084 - val_loss: 1882.3774 - val_regression_loss: 938.4980 - val_tarreg_loss: 1877.6753 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 178/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4772.2910 - regression_loss: 2383.6094 - tarreg_loss: 4767.5889 - treatment_acc: 0.5084 - val_loss: 1881.9329 - val_regression_loss: 938.2754 - val_tarreg_loss: 1877.2307 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 179/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4769.0371 - regression_loss: 2381.9780 - tarreg_loss: 4764.3350 - treatment_acc: 0.5084 - val_loss: 1881.4817 - val_regression_loss: 938.0494 - val_tarreg_loss: 1876.7795 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 180/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4765.6470 - regression_loss: 2380.2808 - tarreg_loss: 4760.9448 - treatment_acc: 0.5084 - val_loss: 1881.0554 - val_regression_loss: 937.8359 - val_tarreg_loss: 1876.3533 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 181/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4762.4512 - regression_loss: 2378.6794 - tarreg_loss: 4757.7490 - treatment_acc: 0.5084 - val_loss: 1880.6688 - val_regression_loss: 937.6423 - val_tarreg_loss: 1875.9667 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 182/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4759.2319 - regression_loss: 2377.0679 - tarreg_loss: 4754.5298 - treatment_acc: 0.5084 - val_loss: 1880.2261 - val_regression_loss: 937.4206 - val_tarreg_loss: 1875.5239 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 183/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4755.9277 - regression_loss: 2375.4116 - tarreg_loss: 4751.2256 - treatment_acc: 0.5084 - val_loss: 1879.8274 - val_regression_loss: 937.2210 - val_tarreg_loss: 1875.1254 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 184/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4752.7090 - regression_loss: 2373.7983 - tarreg_loss: 4748.0068 - treatment_acc: 0.5084 - val_loss: 1879.4260 - val_regression_loss: 937.0200 - val_tarreg_loss: 1874.7241 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 185/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4749.5430 - regression_loss: 2372.2129 - tarreg_loss: 4744.8408 - treatment_acc: 0.5081 - val_loss: 1879.0525 - val_regression_loss: 936.8329 - val_tarreg_loss: 1874.3505 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 186/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4746.3887 - regression_loss: 2370.6326 - tarreg_loss: 4741.6865 - treatment_acc: 0.5084 - val_loss: 1878.6248 - val_regression_loss: 936.6188 - val_tarreg_loss: 1873.9226 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 187/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4743.2095 - regression_loss: 2369.0405 - tarreg_loss: 4738.5073 - treatment_acc: 0.5081 - val_loss: 1878.2073 - val_regression_loss: 936.4098 - val_tarreg_loss: 1873.5054 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 188/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4740.0498 - regression_loss: 2367.4580 - tarreg_loss: 4735.3477 - treatment_acc: 0.5081 - val_loss: 1877.7999 - val_regression_loss: 936.2057 - val_tarreg_loss: 1873.0978 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 189/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4736.8916 - regression_loss: 2365.8760 - tarreg_loss: 4732.1895 - treatment_acc: 0.5081 - val_loss: 1877.4060 - val_regression_loss: 936.0085 - val_tarreg_loss: 1872.7039 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 190/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4733.7573 - regression_loss: 2364.3062 - tarreg_loss: 4729.0552 - treatment_acc: 0.5081 - val_loss: 1876.9969 - val_regression_loss: 935.8038 - val_tarreg_loss: 1872.2949 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 191/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4730.6201 - regression_loss: 2362.7354 - tarreg_loss: 4725.9180 - treatment_acc: 0.5081 - val_loss: 1876.6582 - val_regression_loss: 935.6342 - val_tarreg_loss: 1871.9562 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 192/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4727.5225 - regression_loss: 2361.1831 - tarreg_loss: 4722.8203 - treatment_acc: 0.5078 - val_loss: 1876.2620 - val_regression_loss: 935.4359 - val_tarreg_loss: 1871.5601 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 193/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4724.4639 - regression_loss: 2359.6504 - tarreg_loss: 4719.7617 - treatment_acc: 0.5078 - val_loss: 1875.8876 - val_regression_loss: 935.2484 - val_tarreg_loss: 1871.1857 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 194/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4721.3838 - regression_loss: 2358.1089 - tarreg_loss: 4716.6816 - treatment_acc: 0.5078 - val_loss: 1875.5159 - val_regression_loss: 935.0623 - val_tarreg_loss: 1870.8140 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 195/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4718.3394 - regression_loss: 2356.5837 - tarreg_loss: 4713.6372 - treatment_acc: 0.5078 - val_loss: 1875.1384 - val_regression_loss: 934.8732 - val_tarreg_loss: 1870.4363 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 196/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4715.2871 - regression_loss: 2355.0564 - tarreg_loss: 4710.5850 - treatment_acc: 0.5078 - val_loss: 1874.7812 - val_regression_loss: 934.6943 - val_tarreg_loss: 1870.0792 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 197/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4712.2549 - regression_loss: 2353.5376 - tarreg_loss: 4707.5527 - treatment_acc: 0.5078 - val_loss: 1874.4127 - val_regression_loss: 934.5100 - val_tarreg_loss: 1869.7107 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 198/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4709.2119 - regression_loss: 2352.0142 - tarreg_loss: 4704.5098 - treatment_acc: 0.5078 - val_loss: 1874.0424 - val_regression_loss: 934.3246 - val_tarreg_loss: 1869.3403 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 199/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4706.2725 - regression_loss: 2350.5422 - tarreg_loss: 4701.5703 - treatment_acc: 0.5078 - val_loss: 1873.6901 - val_regression_loss: 934.1481 - val_tarreg_loss: 1868.9880 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 200/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4703.2051 - regression_loss: 2349.0063 - tarreg_loss: 4698.5029 - treatment_acc: 0.5078 - val_loss: 1873.2980 - val_regression_loss: 933.9519 - val_tarreg_loss: 1868.5959 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 201/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4700.2324 - regression_loss: 2347.5186 - tarreg_loss: 4695.5303 - treatment_acc: 0.5078 - val_loss: 1872.9366 - val_regression_loss: 933.7710 - val_tarreg_loss: 1868.2345 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 202/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4697.3379 - regression_loss: 2346.0681 - tarreg_loss: 4692.6357 - treatment_acc: 0.5078 - val_loss: 1872.6014 - val_regression_loss: 933.6031 - val_tarreg_loss: 1867.8994 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 203/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4694.3379 - regression_loss: 2344.5649 - tarreg_loss: 4689.6357 - treatment_acc: 0.5078 - val_loss: 1872.2277 - val_regression_loss: 933.4161 - val_tarreg_loss: 1867.5256 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 204/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4691.4219 - regression_loss: 2343.1055 - tarreg_loss: 4686.7197 - treatment_acc: 0.5081 - val_loss: 1871.9210 - val_regression_loss: 933.2625 - val_tarreg_loss: 1867.2189 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 205/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4688.4248 - regression_loss: 2341.6045 - tarreg_loss: 4683.7227 - treatment_acc: 0.5081 - val_loss: 1871.5819 - val_regression_loss: 933.0927 - val_tarreg_loss: 1866.8799 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 206/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 4685.5605 - regression_loss: 2340.1697 - tarreg_loss: 4680.8584 - treatment_acc: 0.5081 - val_loss: 1871.2126 - val_regression_loss: 932.9078 - val_tarreg_loss: 1866.5105 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 207/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4682.6226 - regression_loss: 2338.6978 - tarreg_loss: 4677.9204 - treatment_acc: 0.5081 - val_loss: 1870.9022 - val_regression_loss: 932.7521 - val_tarreg_loss: 1866.2002 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 208/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4679.7441 - regression_loss: 2337.2576 - tarreg_loss: 4675.0420 - treatment_acc: 0.5081 - val_loss: 1870.5737 - val_regression_loss: 932.5878 - val_tarreg_loss: 1865.8717 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 209/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4676.8696 - regression_loss: 2335.8179 - tarreg_loss: 4672.1680 - treatment_acc: 0.5081 - val_loss: 1870.2600 - val_regression_loss: 932.4307 - val_tarreg_loss: 1865.5580 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 210/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4673.9663 - regression_loss: 2334.3652 - tarreg_loss: 4669.2646 - treatment_acc: 0.5081 - val_loss: 1869.9283 - val_regression_loss: 932.2646 - val_tarreg_loss: 1865.2263 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 211/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4671.0630 - regression_loss: 2332.9111 - tarreg_loss: 4666.3613 - treatment_acc: 0.5081 - val_loss: 1869.6111 - val_regression_loss: 932.1060 - val_tarreg_loss: 1864.9092 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 212/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4668.1519 - regression_loss: 2331.4548 - tarreg_loss: 4663.4502 - treatment_acc: 0.5081 - val_loss: 1869.2704 - val_regression_loss: 931.9355 - val_tarreg_loss: 1864.5686 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 213/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4665.3423 - regression_loss: 2330.0483 - tarreg_loss: 4660.6406 - treatment_acc: 0.5081 - val_loss: 1868.9445 - val_regression_loss: 931.7723 - val_tarreg_loss: 1864.2424 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 214/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4662.5942 - regression_loss: 2328.6726 - tarreg_loss: 4657.8926 - treatment_acc: 0.5081 - val_loss: 1868.6602 - val_regression_loss: 931.6300 - val_tarreg_loss: 1863.9583 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 215/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4659.7524 - regression_loss: 2327.2507 - tarreg_loss: 4655.0508 - treatment_acc: 0.5081 - val_loss: 1868.3101 - val_regression_loss: 931.4548 - val_tarreg_loss: 1863.6082 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 216/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4656.9385 - regression_loss: 2325.8423 - tarreg_loss: 4652.2368 - treatment_acc: 0.5081 - val_loss: 1868.0304 - val_regression_loss: 931.3148 - val_tarreg_loss: 1863.3284 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 217/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4654.1245 - regression_loss: 2324.4346 - tarreg_loss: 4649.4229 - treatment_acc: 0.5081 - val_loss: 1867.7097 - val_regression_loss: 931.1544 - val_tarreg_loss: 1863.0078 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 218/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4651.3223 - regression_loss: 2323.0327 - tarreg_loss: 4646.6206 - treatment_acc: 0.5081 - val_loss: 1867.4348 - val_regression_loss: 931.0167 - val_tarreg_loss: 1862.7329 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 219/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4648.5547 - regression_loss: 2321.6472 - tarreg_loss: 4643.8530 - treatment_acc: 0.5081 - val_loss: 1867.0968 - val_regression_loss: 930.8475 - val_tarreg_loss: 1862.3948 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 220/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4645.7808 - regression_loss: 2320.2588 - tarreg_loss: 4641.0791 - treatment_acc: 0.5078 - val_loss: 1866.8019 - val_regression_loss: 930.7000 - val_tarreg_loss: 1862.0999 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 221/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4643.0229 - regression_loss: 2318.8789 - tarreg_loss: 4638.3213 - treatment_acc: 0.5078 - val_loss: 1866.4991 - val_regression_loss: 930.5484 - val_tarreg_loss: 1861.7971 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 222/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4640.2817 - regression_loss: 2317.5071 - tarreg_loss: 4635.5801 - treatment_acc: 0.5078 - val_loss: 1866.1942 - val_regression_loss: 930.3958 - val_tarreg_loss: 1861.4922 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 223/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4637.4961 - regression_loss: 2316.1128 - tarreg_loss: 4632.7944 - treatment_acc: 0.5075 - val_loss: 1865.9143 - val_regression_loss: 930.2557 - val_tarreg_loss: 1861.2124 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 224/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4634.8047 - regression_loss: 2314.7651 - tarreg_loss: 4630.1030 - treatment_acc: 0.5075 - val_loss: 1865.6011 - val_regression_loss: 930.0988 - val_tarreg_loss: 1860.8990 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 225/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4632.0898 - regression_loss: 2313.4072 - tarreg_loss: 4627.3882 - treatment_acc: 0.5072 - val_loss: 1865.3337 - val_regression_loss: 929.9650 - val_tarreg_loss: 1860.6316 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 226/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4629.3218 - regression_loss: 2312.0217 - tarreg_loss: 4624.6201 - treatment_acc: 0.5072 - val_loss: 1865.0450 - val_regression_loss: 929.8205 - val_tarreg_loss: 1860.3430 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 227/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4626.6694 - regression_loss: 2310.6951 - tarreg_loss: 4621.9678 - treatment_acc: 0.5072 - val_loss: 1864.7826 - val_regression_loss: 929.6892 - val_tarreg_loss: 1860.0806 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 228/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4623.9116 - regression_loss: 2309.3145 - tarreg_loss: 4619.2100 - treatment_acc: 0.5075 - val_loss: 1864.5295 - val_regression_loss: 929.5626 - val_tarreg_loss: 1859.8276 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 229/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4621.2778 - regression_loss: 2307.9949 - tarreg_loss: 4616.5762 - treatment_acc: 0.5072 - val_loss: 1864.2063 - val_regression_loss: 929.4007 - val_tarreg_loss: 1859.5044 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 230/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4618.5420 - regression_loss: 2306.6260 - tarreg_loss: 4613.8403 - treatment_acc: 0.5072 - val_loss: 1863.9407 - val_regression_loss: 929.2678 - val_tarreg_loss: 1859.2388 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 231/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4615.9702 - regression_loss: 2305.3396 - tarreg_loss: 4611.2686 - treatment_acc: 0.5069 - val_loss: 1863.6398 - val_regression_loss: 929.1171 - val_tarreg_loss: 1858.9377 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 232/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4613.2173 - regression_loss: 2303.9609 - tarreg_loss: 4608.5156 - treatment_acc: 0.5069 - val_loss: 1863.3418 - val_regression_loss: 928.9680 - val_tarreg_loss: 1858.6399 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 233/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4610.5820 - regression_loss: 2302.6423 - tarreg_loss: 4605.8804 - treatment_acc: 0.5069 - val_loss: 1863.1011 - val_regression_loss: 928.8475 - val_tarreg_loss: 1858.3992 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 234/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4607.9663 - regression_loss: 2301.3335 - tarreg_loss: 4603.2646 - treatment_acc: 0.5069 - val_loss: 1862.8416 - val_regression_loss: 928.7175 - val_tarreg_loss: 1858.1396 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 235/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4605.3096 - regression_loss: 2300.0039 - tarreg_loss: 4600.6079 - treatment_acc: 0.5069 - val_loss: 1862.5734 - val_regression_loss: 928.5833 - val_tarreg_loss: 1857.8713 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 236/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4602.7153 - regression_loss: 2298.7056 - tarreg_loss: 4598.0137 - treatment_acc: 0.5066 - val_loss: 1862.3491 - val_regression_loss: 928.4711 - val_tarreg_loss: 1857.6472 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 237/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4600.1167 - regression_loss: 2297.4045 - tarreg_loss: 4595.4150 - treatment_acc: 0.5069 - val_loss: 1862.0858 - val_regression_loss: 928.3392 - val_tarreg_loss: 1857.3839 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 238/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4597.5181 - regression_loss: 2296.1040 - tarreg_loss: 4592.8164 - treatment_acc: 0.5072 - val_loss: 1861.8009 - val_regression_loss: 928.1967 - val_tarreg_loss: 1857.0990 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 239/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4594.9258 - regression_loss: 2294.8074 - tarreg_loss: 4590.2246 - treatment_acc: 0.5075 - val_loss: 1861.5835 - val_regression_loss: 928.0878 - val_tarreg_loss: 1856.8816 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 240/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4592.2871 - regression_loss: 2293.4868 - tarreg_loss: 4587.5859 - treatment_acc: 0.5075 - val_loss: 1861.3185 - val_regression_loss: 927.9552 - val_tarreg_loss: 1856.6166 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 241/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4589.7188 - regression_loss: 2292.2017 - tarreg_loss: 4585.0176 - treatment_acc: 0.5075 - val_loss: 1861.0598 - val_regression_loss: 927.8256 - val_tarreg_loss: 1856.3579 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 242/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4587.0977 - regression_loss: 2290.8909 - tarreg_loss: 4582.3965 - treatment_acc: 0.5075 - val_loss: 1860.8206 - val_regression_loss: 927.7059 - val_tarreg_loss: 1856.1187 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 243/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4584.5977 - regression_loss: 2289.6401 - tarreg_loss: 4579.8965 - treatment_acc: 0.5072 - val_loss: 1860.5890 - val_regression_loss: 927.5900 - val_tarreg_loss: 1855.8870 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 244/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4582.0078 - regression_loss: 2288.3438 - tarreg_loss: 4577.3066 - treatment_acc: 0.5072 - val_loss: 1860.3335 - val_regression_loss: 927.4622 - val_tarreg_loss: 1855.6316 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 245/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4579.4565 - regression_loss: 2287.0671 - tarreg_loss: 4574.7554 - treatment_acc: 0.5069 - val_loss: 1860.1014 - val_regression_loss: 927.3461 - val_tarreg_loss: 1855.3995 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 246/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4576.9121 - regression_loss: 2285.7944 - tarreg_loss: 4572.2109 - treatment_acc: 0.5069 - val_loss: 1859.8733 - val_regression_loss: 927.2319 - val_tarreg_loss: 1855.1714 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 247/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4574.3359 - regression_loss: 2284.5049 - tarreg_loss: 4569.6348 - treatment_acc: 0.5069 - val_loss: 1859.6050 - val_regression_loss: 927.0976 - val_tarreg_loss: 1854.9031 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 248/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4571.7954 - regression_loss: 2283.2339 - tarreg_loss: 4567.0942 - treatment_acc: 0.5069 - val_loss: 1859.3591 - val_regression_loss: 926.9746 - val_tarreg_loss: 1854.6572 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 249/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4569.2271 - regression_loss: 2281.9482 - tarreg_loss: 4564.5259 - treatment_acc: 0.5069 - val_loss: 1859.1310 - val_regression_loss: 926.8604 - val_tarreg_loss: 1854.4291 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 250/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4566.7310 - regression_loss: 2280.6987 - tarreg_loss: 4562.0293 - treatment_acc: 0.5069 - val_loss: 1858.8884 - val_regression_loss: 926.7388 - val_tarreg_loss: 1854.1865 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 251/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4564.2573 - regression_loss: 2279.4604 - tarreg_loss: 4559.5557 - treatment_acc: 0.5069 - val_loss: 1858.6824 - val_regression_loss: 926.6356 - val_tarreg_loss: 1853.9805 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 252/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4561.7979 - regression_loss: 2278.2297 - tarreg_loss: 4557.0962 - treatment_acc: 0.5069 - val_loss: 1858.4210 - val_regression_loss: 926.5048 - val_tarreg_loss: 1853.7190 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 253/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4559.3018 - regression_loss: 2276.9812 - tarreg_loss: 4554.6001 - treatment_acc: 0.5066 - val_loss: 1858.2194 - val_regression_loss: 926.4038 - val_tarreg_loss: 1853.5173 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 254/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4556.7603 - regression_loss: 2275.7097 - tarreg_loss: 4552.0586 - treatment_acc: 0.5066 - val_loss: 1857.9685 - val_regression_loss: 926.2782 - val_tarreg_loss: 1853.2664 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 255/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 4554.3306 - regression_loss: 2274.4944 - tarreg_loss: 4549.6289 - treatment_acc: 0.5069 - val_loss: 1857.7743 - val_regression_loss: 926.1811 - val_tarreg_loss: 1853.0723 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 256/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4551.8545 - regression_loss: 2273.2559 - tarreg_loss: 4547.1528 - treatment_acc: 0.5069 - val_loss: 1857.5927 - val_regression_loss: 926.0901 - val_tarreg_loss: 1852.8906 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 257/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4549.4077 - regression_loss: 2272.0317 - tarreg_loss: 4544.7061 - treatment_acc: 0.5069 - val_loss: 1857.2963 - val_regression_loss: 925.9420 - val_tarreg_loss: 1852.5942 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 258/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4546.9106 - regression_loss: 2270.7827 - tarreg_loss: 4542.2090 - treatment_acc: 0.5069 - val_loss: 1857.0784 - val_regression_loss: 925.8329 - val_tarreg_loss: 1852.3763 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 259/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4544.4673 - regression_loss: 2269.5601 - tarreg_loss: 4539.7656 - treatment_acc: 0.5072 - val_loss: 1856.8875 - val_regression_loss: 925.7374 - val_tarreg_loss: 1852.1854 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 260/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4542.0718 - regression_loss: 2268.3616 - tarreg_loss: 4537.3701 - treatment_acc: 0.5072 - val_loss: 1856.6600 - val_regression_loss: 925.6235 - val_tarreg_loss: 1851.9580 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 261/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4539.6157 - regression_loss: 2267.1326 - tarreg_loss: 4534.9136 - treatment_acc: 0.5072 - val_loss: 1856.4669 - val_regression_loss: 925.5270 - val_tarreg_loss: 1851.7649 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 262/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4537.2188 - regression_loss: 2265.9333 - tarreg_loss: 4532.5166 - treatment_acc: 0.5072 - val_loss: 1856.2858 - val_regression_loss: 925.4362 - val_tarreg_loss: 1851.5837 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 263/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4534.7925 - regression_loss: 2264.7197 - tarreg_loss: 4530.0903 - treatment_acc: 0.5072 - val_loss: 1856.0631 - val_regression_loss: 925.3248 - val_tarreg_loss: 1851.3611 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 264/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4532.3892 - regression_loss: 2263.5178 - tarreg_loss: 4527.6870 - treatment_acc: 0.5069 - val_loss: 1855.8741 - val_regression_loss: 925.2301 - val_tarreg_loss: 1851.1720 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 265/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4529.9839 - regression_loss: 2262.3140 - tarreg_loss: 4525.2817 - treatment_acc: 0.5069 - val_loss: 1855.6698 - val_regression_loss: 925.1279 - val_tarreg_loss: 1850.9678 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 266/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4527.5449 - regression_loss: 2261.0940 - tarreg_loss: 4522.8428 - treatment_acc: 0.5066 - val_loss: 1855.4779 - val_regression_loss: 925.0319 - val_tarreg_loss: 1850.7759 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 267/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4525.1055 - regression_loss: 2259.8733 - tarreg_loss: 4520.4033 - treatment_acc: 0.5066 - val_loss: 1855.2717 - val_regression_loss: 924.9286 - val_tarreg_loss: 1850.5697 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 268/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4522.7676 - regression_loss: 2258.7031 - tarreg_loss: 4518.0654 - treatment_acc: 0.5066 - val_loss: 1855.0681 - val_regression_loss: 924.8268 - val_tarreg_loss: 1850.3661 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 269/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4520.3818 - regression_loss: 2257.5100 - tarreg_loss: 4515.6797 - treatment_acc: 0.5066 - val_loss: 1854.8420 - val_regression_loss: 924.7137 - val_tarreg_loss: 1850.1401 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 270/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4518.0117 - regression_loss: 2256.3250 - tarreg_loss: 4513.3096 - treatment_acc: 0.5066 - val_loss: 1854.6716 - val_regression_loss: 924.6284 - val_tarreg_loss: 1849.9697 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 271/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4515.5967 - regression_loss: 2255.1167 - tarreg_loss: 4510.8945 - treatment_acc: 0.5066 - val_loss: 1854.5013 - val_regression_loss: 924.5432 - val_tarreg_loss: 1849.7994 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 272/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4513.2119 - regression_loss: 2253.9238 - tarreg_loss: 4508.5098 - treatment_acc: 0.5066 - val_loss: 1854.3287 - val_regression_loss: 924.4568 - val_tarreg_loss: 1849.6268 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 273/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4510.8770 - regression_loss: 2252.7559 - tarreg_loss: 4506.1748 - treatment_acc: 0.5063 - val_loss: 1854.0916 - val_regression_loss: 924.3381 - val_tarreg_loss: 1849.3896 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 274/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4508.5273 - regression_loss: 2251.5808 - tarreg_loss: 4503.8252 - treatment_acc: 0.5063 - val_loss: 1853.9232 - val_regression_loss: 924.2540 - val_tarreg_loss: 1849.2213 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 275/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4506.2520 - regression_loss: 2250.4434 - tarreg_loss: 4501.5498 - treatment_acc: 0.5063 - val_loss: 1853.7469 - val_regression_loss: 924.1657 - val_tarreg_loss: 1849.0449 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 276/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4503.8672 - regression_loss: 2249.2502 - tarreg_loss: 4499.1650 - treatment_acc: 0.5066 - val_loss: 1853.5223 - val_regression_loss: 924.0534 - val_tarreg_loss: 1848.8203 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 277/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4501.5503 - regression_loss: 2248.0911 - tarreg_loss: 4496.8481 - treatment_acc: 0.5063 - val_loss: 1853.3326 - val_regression_loss: 923.9585 - val_tarreg_loss: 1848.6306 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 278/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4499.1924 - regression_loss: 2246.9114 - tarreg_loss: 4494.4902 - treatment_acc: 0.5063 - val_loss: 1853.1537 - val_regression_loss: 923.8690 - val_tarreg_loss: 1848.4517 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 279/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4496.8442 - regression_loss: 2245.7363 - tarreg_loss: 4492.1421 - treatment_acc: 0.5063 - val_loss: 1853.0111 - val_regression_loss: 923.7975 - val_tarreg_loss: 1848.3091 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 280/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4494.5273 - regression_loss: 2244.5774 - tarreg_loss: 4489.8252 - treatment_acc: 0.5063 - val_loss: 1852.8358 - val_regression_loss: 923.7097 - val_tarreg_loss: 1848.1338 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 281/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4492.2612 - regression_loss: 2243.4441 - tarreg_loss: 4487.5591 - treatment_acc: 0.5063 - val_loss: 1852.6489 - val_regression_loss: 923.6163 - val_tarreg_loss: 1847.9469 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 282/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4489.9355 - regression_loss: 2242.2808 - tarreg_loss: 4485.2334 - treatment_acc: 0.5063 - val_loss: 1852.4844 - val_regression_loss: 923.5338 - val_tarreg_loss: 1847.7822 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 283/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4487.6411 - regression_loss: 2241.1328 - tarreg_loss: 4482.9390 - treatment_acc: 0.5060 - val_loss: 1852.2820 - val_regression_loss: 923.4325 - val_tarreg_loss: 1847.5798 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 284/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4485.3013 - regression_loss: 2239.9634 - tarreg_loss: 4480.5991 - treatment_acc: 0.5057 - val_loss: 1852.1284 - val_regression_loss: 923.3557 - val_tarreg_loss: 1847.4263 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 285/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4483.0449 - regression_loss: 2238.8350 - tarreg_loss: 4478.3428 - treatment_acc: 0.5057 - val_loss: 1851.9406 - val_regression_loss: 923.2616 - val_tarreg_loss: 1847.2383 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 286/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4480.7119 - regression_loss: 2237.6675 - tarreg_loss: 4476.0098 - treatment_acc: 0.5057 - val_loss: 1851.7463 - val_regression_loss: 923.1646 - val_tarreg_loss: 1847.0443 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 287/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4478.4292 - regression_loss: 2236.5251 - tarreg_loss: 4473.7271 - treatment_acc: 0.5054 - val_loss: 1851.6241 - val_regression_loss: 923.1034 - val_tarreg_loss: 1846.9219 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 288/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4476.1484 - regression_loss: 2235.3845 - tarreg_loss: 4471.4463 - treatment_acc: 0.5054 - val_loss: 1851.4076 - val_regression_loss: 922.9951 - val_tarreg_loss: 1846.7054 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 289/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4473.8403 - regression_loss: 2234.2300 - tarreg_loss: 4469.1382 - treatment_acc: 0.5051 - val_loss: 1851.2732 - val_regression_loss: 922.9277 - val_tarreg_loss: 1846.5709 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 290/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4471.5493 - regression_loss: 2233.0840 - tarreg_loss: 4466.8472 - treatment_acc: 0.5051 - val_loss: 1851.0964 - val_regression_loss: 922.8394 - val_tarreg_loss: 1846.3943 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 291/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4469.3828 - regression_loss: 2232.0007 - tarreg_loss: 4464.6807 - treatment_acc: 0.5054 - val_loss: 1850.9094 - val_regression_loss: 922.7457 - val_tarreg_loss: 1846.2073 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 292/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4467.1045 - regression_loss: 2230.8608 - tarreg_loss: 4462.4023 - treatment_acc: 0.5054 - val_loss: 1850.7938 - val_regression_loss: 922.6879 - val_tarreg_loss: 1846.0918 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 293/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4464.8706 - regression_loss: 2229.7437 - tarreg_loss: 4460.1685 - treatment_acc: 0.5057 - val_loss: 1850.6440 - val_regression_loss: 922.6129 - val_tarreg_loss: 1845.9419 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 294/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4462.6230 - regression_loss: 2228.6184 - tarreg_loss: 4457.9209 - treatment_acc: 0.5054 - val_loss: 1850.4692 - val_regression_loss: 922.5253 - val_tarreg_loss: 1845.7671 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 295/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4460.3589 - regression_loss: 2227.4858 - tarreg_loss: 4455.6567 - treatment_acc: 0.5054 - val_loss: 1850.3055 - val_regression_loss: 922.4434 - val_tarreg_loss: 1845.6035 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 296/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4458.1719 - regression_loss: 2226.3921 - tarreg_loss: 4453.4697 - treatment_acc: 0.5054 - val_loss: 1850.1306 - val_regression_loss: 922.3558 - val_tarreg_loss: 1845.4283 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 297/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4455.9873 - regression_loss: 2225.2993 - tarreg_loss: 4451.2852 - treatment_acc: 0.5054 - val_loss: 1849.9637 - val_regression_loss: 922.2724 - val_tarreg_loss: 1845.2616 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 298/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4453.7754 - regression_loss: 2224.1934 - tarreg_loss: 4449.0732 - treatment_acc: 0.5054 - val_loss: 1849.8250 - val_regression_loss: 922.2029 - val_tarreg_loss: 1845.1228 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 299/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4451.5117 - regression_loss: 2223.0610 - tarreg_loss: 4446.8096 - treatment_acc: 0.5054 - val_loss: 1849.6906 - val_regression_loss: 922.1357 - val_tarreg_loss: 1844.9883 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 300/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4449.3281 - regression_loss: 2221.9688 - tarreg_loss: 4444.6260 - treatment_acc: 0.5054 - val_loss: 1849.4943 - val_regression_loss: 922.0375 - val_tarreg_loss: 1844.7921 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 301/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4447.0488 - regression_loss: 2220.8289 - tarreg_loss: 4442.3467 - treatment_acc: 0.5054 - val_loss: 1849.3599 - val_regression_loss: 921.9703 - val_tarreg_loss: 1844.6577 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 302/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4444.8452 - regression_loss: 2219.7275 - tarreg_loss: 4440.1431 - treatment_acc: 0.5057 - val_loss: 1849.2400 - val_regression_loss: 921.9103 - val_tarreg_loss: 1844.5378 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 303/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4442.6045 - regression_loss: 2218.6072 - tarreg_loss: 4437.9023 - treatment_acc: 0.5057 - val_loss: 1849.1091 - val_regression_loss: 921.8450 - val_tarreg_loss: 1844.4071 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 304/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4440.4473 - regression_loss: 2217.5283 - tarreg_loss: 4435.7451 - treatment_acc: 0.5060 - val_loss: 1848.9631 - val_regression_loss: 921.7720 - val_tarreg_loss: 1844.2612 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 305/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4438.2637 - regression_loss: 2216.4358 - tarreg_loss: 4433.5615 - treatment_acc: 0.5060 - val_loss: 1848.8308 - val_regression_loss: 921.7057 - val_tarreg_loss: 1844.1288 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 306/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4436.0801 - regression_loss: 2215.3435 - tarreg_loss: 4431.3779 - treatment_acc: 0.5060 - val_loss: 1848.6752 - val_regression_loss: 921.6279 - val_tarreg_loss: 1843.9731 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 307/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 4433.9458 - regression_loss: 2214.2766 - tarreg_loss: 4429.2437 - treatment_acc: 0.5060 - val_loss: 1848.5441 - val_regression_loss: 921.5623 - val_tarreg_loss: 1843.8420 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 308/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4431.7603 - regression_loss: 2213.1836 - tarreg_loss: 4427.0581 - treatment_acc: 0.5060 - val_loss: 1848.4124 - val_regression_loss: 921.4964 - val_tarreg_loss: 1843.7104 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 309/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4429.5791 - regression_loss: 2212.0925 - tarreg_loss: 4424.8770 - treatment_acc: 0.5060 - val_loss: 1848.2845 - val_regression_loss: 921.4323 - val_tarreg_loss: 1843.5825 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 310/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4427.4014 - regression_loss: 2211.0032 - tarreg_loss: 4422.6992 - treatment_acc: 0.5060 - val_loss: 1848.1584 - val_regression_loss: 921.3693 - val_tarreg_loss: 1843.4565 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 311/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4425.2188 - regression_loss: 2209.9114 - tarreg_loss: 4420.5166 - treatment_acc: 0.5060 - val_loss: 1848.0173 - val_regression_loss: 921.2986 - val_tarreg_loss: 1843.3153 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 312/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4423.0015 - regression_loss: 2208.8030 - tarreg_loss: 4418.2993 - treatment_acc: 0.5060 - val_loss: 1847.8729 - val_regression_loss: 921.2264 - val_tarreg_loss: 1843.1709 - val_treatment_acc: 0.5276 - learning_rate: 6.0000e-08\n","Epoch 313/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4420.8545 - regression_loss: 2207.7295 - tarreg_loss: 4416.1523 - treatment_acc: 0.5060 - val_loss: 1847.7494 - val_regression_loss: 921.1646 - val_tarreg_loss: 1843.0474 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 314/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4418.7305 - regression_loss: 2206.6672 - tarreg_loss: 4414.0283 - treatment_acc: 0.5060 - val_loss: 1847.6116 - val_regression_loss: 921.0956 - val_tarreg_loss: 1842.9097 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 315/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4416.5811 - regression_loss: 2205.5916 - tarreg_loss: 4411.8789 - treatment_acc: 0.5060 - val_loss: 1847.4972 - val_regression_loss: 921.0384 - val_tarreg_loss: 1842.7952 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 316/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4414.4385 - regression_loss: 2204.5205 - tarreg_loss: 4409.7363 - treatment_acc: 0.5060 - val_loss: 1847.3907 - val_regression_loss: 920.9851 - val_tarreg_loss: 1842.6887 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 317/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4412.3188 - regression_loss: 2203.4604 - tarreg_loss: 4407.6167 - treatment_acc: 0.5060 - val_loss: 1847.2283 - val_regression_loss: 920.9037 - val_tarreg_loss: 1842.5261 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 318/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4410.1812 - regression_loss: 2202.3906 - tarreg_loss: 4405.4790 - treatment_acc: 0.5060 - val_loss: 1847.0784 - val_regression_loss: 920.8289 - val_tarreg_loss: 1842.3765 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 319/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4408.0371 - regression_loss: 2201.3186 - tarreg_loss: 4403.3350 - treatment_acc: 0.5060 - val_loss: 1846.9993 - val_regression_loss: 920.7892 - val_tarreg_loss: 1842.2971 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 320/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4405.9185 - regression_loss: 2200.2588 - tarreg_loss: 4401.2163 - treatment_acc: 0.5060 - val_loss: 1846.8770 - val_regression_loss: 920.7279 - val_tarreg_loss: 1842.1748 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 321/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4403.8223 - regression_loss: 2199.2104 - tarreg_loss: 4399.1201 - treatment_acc: 0.5060 - val_loss: 1846.7634 - val_regression_loss: 920.6710 - val_tarreg_loss: 1842.0613 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 322/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4401.6831 - regression_loss: 2198.1406 - tarreg_loss: 4396.9810 - treatment_acc: 0.5057 - val_loss: 1846.6448 - val_regression_loss: 920.6116 - val_tarreg_loss: 1841.9426 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 323/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4399.5649 - regression_loss: 2197.0811 - tarreg_loss: 4394.8628 - treatment_acc: 0.5057 - val_loss: 1846.5374 - val_regression_loss: 920.5579 - val_tarreg_loss: 1841.8351 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 324/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4397.4971 - regression_loss: 2196.0471 - tarreg_loss: 4392.7949 - treatment_acc: 0.5057 - val_loss: 1846.4076 - val_regression_loss: 920.4929 - val_tarreg_loss: 1841.7053 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 325/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4395.3838 - regression_loss: 2194.9900 - tarreg_loss: 4390.6816 - treatment_acc: 0.5057 - val_loss: 1846.3108 - val_regression_loss: 920.4445 - val_tarreg_loss: 1841.6085 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 326/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4393.3149 - regression_loss: 2193.9551 - tarreg_loss: 4388.6128 - treatment_acc: 0.5057 - val_loss: 1846.2048 - val_regression_loss: 920.3914 - val_tarreg_loss: 1841.5024 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 327/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4391.1553 - regression_loss: 2192.8752 - tarreg_loss: 4386.4531 - treatment_acc: 0.5057 - val_loss: 1846.0544 - val_regression_loss: 920.3162 - val_tarreg_loss: 1841.3521 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 328/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4389.0645 - regression_loss: 2191.8296 - tarreg_loss: 4384.3623 - treatment_acc: 0.5057 - val_loss: 1845.9305 - val_regression_loss: 920.2543 - val_tarreg_loss: 1841.2283 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 329/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4387.0225 - regression_loss: 2190.8088 - tarreg_loss: 4382.3203 - treatment_acc: 0.5060 - val_loss: 1845.8080 - val_regression_loss: 920.1930 - val_tarreg_loss: 1841.1057 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 330/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4384.8950 - regression_loss: 2189.7451 - tarreg_loss: 4380.1929 - treatment_acc: 0.5060 - val_loss: 1845.7319 - val_regression_loss: 920.1549 - val_tarreg_loss: 1841.0297 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 331/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4382.8091 - regression_loss: 2188.7017 - tarreg_loss: 4378.1069 - treatment_acc: 0.5060 - val_loss: 1845.6169 - val_regression_loss: 920.0974 - val_tarreg_loss: 1840.9146 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 332/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4380.7739 - regression_loss: 2187.6838 - tarreg_loss: 4376.0718 - treatment_acc: 0.5060 - val_loss: 1845.4955 - val_regression_loss: 920.0367 - val_tarreg_loss: 1840.7932 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 333/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4378.7393 - regression_loss: 2186.6663 - tarreg_loss: 4374.0371 - treatment_acc: 0.5060 - val_loss: 1845.3884 - val_regression_loss: 919.9830 - val_tarreg_loss: 1840.6860 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 334/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4376.5952 - regression_loss: 2185.5942 - tarreg_loss: 4371.8931 - treatment_acc: 0.5060 - val_loss: 1845.3032 - val_regression_loss: 919.9404 - val_tarreg_loss: 1840.6010 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 335/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4374.4932 - regression_loss: 2184.5432 - tarreg_loss: 4369.7910 - treatment_acc: 0.5060 - val_loss: 1845.1853 - val_regression_loss: 919.8815 - val_tarreg_loss: 1840.4830 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 336/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4372.4434 - regression_loss: 2183.5178 - tarreg_loss: 4367.7412 - treatment_acc: 0.5060 - val_loss: 1845.0763 - val_regression_loss: 919.8269 - val_tarreg_loss: 1840.3740 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 337/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4370.3984 - regression_loss: 2182.4951 - tarreg_loss: 4365.6963 - treatment_acc: 0.5060 - val_loss: 1844.9615 - val_regression_loss: 919.7695 - val_tarreg_loss: 1840.2593 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 338/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4368.3799 - regression_loss: 2181.4861 - tarreg_loss: 4363.6777 - treatment_acc: 0.5060 - val_loss: 1844.8964 - val_regression_loss: 919.7369 - val_tarreg_loss: 1840.1941 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 339/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4366.3281 - regression_loss: 2180.4595 - tarreg_loss: 4361.6260 - treatment_acc: 0.5060 - val_loss: 1844.7721 - val_regression_loss: 919.6746 - val_tarreg_loss: 1840.0698 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 340/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4364.2725 - regression_loss: 2179.4316 - tarreg_loss: 4359.5703 - treatment_acc: 0.5060 - val_loss: 1844.6914 - val_regression_loss: 919.6343 - val_tarreg_loss: 1839.9891 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 341/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4362.2480 - regression_loss: 2178.4192 - tarreg_loss: 4357.5459 - treatment_acc: 0.5060 - val_loss: 1844.6146 - val_regression_loss: 919.5959 - val_tarreg_loss: 1839.9124 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 342/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4360.1758 - regression_loss: 2177.3835 - tarreg_loss: 4355.4736 - treatment_acc: 0.5060 - val_loss: 1844.4718 - val_regression_loss: 919.5244 - val_tarreg_loss: 1839.7695 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 343/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4358.0986 - regression_loss: 2176.3445 - tarreg_loss: 4353.3965 - treatment_acc: 0.5060 - val_loss: 1844.3700 - val_regression_loss: 919.4736 - val_tarreg_loss: 1839.6678 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 344/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4356.0596 - regression_loss: 2175.3247 - tarreg_loss: 4351.3574 - treatment_acc: 0.5060 - val_loss: 1844.2747 - val_regression_loss: 919.4259 - val_tarreg_loss: 1839.5725 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 345/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4354.1045 - regression_loss: 2174.3474 - tarreg_loss: 4349.4023 - treatment_acc: 0.5060 - val_loss: 1844.1970 - val_regression_loss: 919.3871 - val_tarreg_loss: 1839.4949 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 346/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4352.0371 - regression_loss: 2173.3140 - tarreg_loss: 4347.3350 - treatment_acc: 0.5060 - val_loss: 1844.0610 - val_regression_loss: 919.3190 - val_tarreg_loss: 1839.3589 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 347/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4349.9854 - regression_loss: 2172.2876 - tarreg_loss: 4345.2832 - treatment_acc: 0.5060 - val_loss: 1843.9646 - val_regression_loss: 919.2708 - val_tarreg_loss: 1839.2625 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 348/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4347.9941 - regression_loss: 2171.2917 - tarreg_loss: 4343.2920 - treatment_acc: 0.5060 - val_loss: 1843.8717 - val_regression_loss: 919.2244 - val_tarreg_loss: 1839.1696 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 349/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4345.9775 - regression_loss: 2170.2832 - tarreg_loss: 4341.2754 - treatment_acc: 0.5060 - val_loss: 1843.8169 - val_regression_loss: 919.1968 - val_tarreg_loss: 1839.1147 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 350/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4343.9834 - regression_loss: 2169.2859 - tarreg_loss: 4339.2812 - treatment_acc: 0.5060 - val_loss: 1843.7240 - val_regression_loss: 919.1504 - val_tarreg_loss: 1839.0219 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 351/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4341.9990 - regression_loss: 2168.2935 - tarreg_loss: 4337.2969 - treatment_acc: 0.5060 - val_loss: 1843.6385 - val_regression_loss: 919.1076 - val_tarreg_loss: 1838.9363 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 352/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4339.9814 - regression_loss: 2167.2847 - tarreg_loss: 4335.2793 - treatment_acc: 0.5060 - val_loss: 1843.5149 - val_regression_loss: 919.0457 - val_tarreg_loss: 1838.8126 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 353/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4337.9355 - regression_loss: 2166.2615 - tarreg_loss: 4333.2334 - treatment_acc: 0.5060 - val_loss: 1843.4325 - val_regression_loss: 919.0044 - val_tarreg_loss: 1838.7302 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 354/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4335.9746 - regression_loss: 2165.2808 - tarreg_loss: 4331.2725 - treatment_acc: 0.5060 - val_loss: 1843.3580 - val_regression_loss: 918.9672 - val_tarreg_loss: 1838.6558 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 355/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4333.9658 - regression_loss: 2164.2764 - tarreg_loss: 4329.2637 - treatment_acc: 0.5060 - val_loss: 1843.2927 - val_regression_loss: 918.9343 - val_tarreg_loss: 1838.5903 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 356/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4331.9512 - regression_loss: 2163.2690 - tarreg_loss: 4327.2490 - treatment_acc: 0.5060 - val_loss: 1843.2009 - val_regression_loss: 918.8885 - val_tarreg_loss: 1838.4985 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 357/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4329.9414 - regression_loss: 2162.2639 - tarreg_loss: 4325.2393 - treatment_acc: 0.5060 - val_loss: 1843.0930 - val_regression_loss: 918.8346 - val_tarreg_loss: 1838.3907 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 358/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4327.9746 - regression_loss: 2161.2805 - tarreg_loss: 4323.2725 - treatment_acc: 0.5060 - val_loss: 1843.0466 - val_regression_loss: 918.8114 - val_tarreg_loss: 1838.3444 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 359/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4325.9849 - regression_loss: 2160.2854 - tarreg_loss: 4321.2827 - treatment_acc: 0.5060 - val_loss: 1842.9962 - val_regression_loss: 918.7860 - val_tarreg_loss: 1838.2937 - val_treatment_acc: 0.5264 - learning_rate: 6.0000e-08\n","Epoch 360/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4324.0405 - regression_loss: 2159.3132 - tarreg_loss: 4319.3384 - treatment_acc: 0.5060 - val_loss: 1842.8627 - val_regression_loss: 918.7192 - val_tarreg_loss: 1838.1602 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 361/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4322.0059 - regression_loss: 2158.2957 - tarreg_loss: 4317.3037 - treatment_acc: 0.5057 - val_loss: 1842.7776 - val_regression_loss: 918.6768 - val_tarreg_loss: 1838.0752 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 362/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4320.0625 - regression_loss: 2157.3237 - tarreg_loss: 4315.3604 - treatment_acc: 0.5057 - val_loss: 1842.6986 - val_regression_loss: 918.6372 - val_tarreg_loss: 1837.9961 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 363/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4318.0508 - regression_loss: 2156.3179 - tarreg_loss: 4313.3486 - treatment_acc: 0.5057 - val_loss: 1842.6399 - val_regression_loss: 918.6077 - val_tarreg_loss: 1837.9374 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 364/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4316.1006 - regression_loss: 2155.3425 - tarreg_loss: 4311.3984 - treatment_acc: 0.5057 - val_loss: 1842.5876 - val_regression_loss: 918.5815 - val_tarreg_loss: 1837.8850 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 365/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4314.1445 - regression_loss: 2154.3643 - tarreg_loss: 4309.4424 - treatment_acc: 0.5057 - val_loss: 1842.5031 - val_regression_loss: 918.5392 - val_tarreg_loss: 1837.8005 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 366/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4312.2031 - regression_loss: 2153.3936 - tarreg_loss: 4307.5010 - treatment_acc: 0.5057 - val_loss: 1842.4303 - val_regression_loss: 918.5027 - val_tarreg_loss: 1837.7278 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 367/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4310.2275 - regression_loss: 2152.4055 - tarreg_loss: 4305.5254 - treatment_acc: 0.5057 - val_loss: 1842.3485 - val_regression_loss: 918.4619 - val_tarreg_loss: 1837.6460 - val_treatment_acc: 0.5252 - learning_rate: 6.0000e-08\n","Epoch 368/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4308.2422 - regression_loss: 2151.4126 - tarreg_loss: 4303.5400 - treatment_acc: 0.5057 - val_loss: 1842.2635 - val_regression_loss: 918.4194 - val_tarreg_loss: 1837.5610 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 369/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4306.3882 - regression_loss: 2150.4858 - tarreg_loss: 4301.6860 - treatment_acc: 0.5057 - val_loss: 1842.2181 - val_regression_loss: 918.3967 - val_tarreg_loss: 1837.5156 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 370/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4304.3887 - regression_loss: 2149.4858 - tarreg_loss: 4299.6865 - treatment_acc: 0.5057 - val_loss: 1842.1599 - val_regression_loss: 918.3676 - val_tarreg_loss: 1837.4573 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 371/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4302.3584 - regression_loss: 2148.4705 - tarreg_loss: 4297.6562 - treatment_acc: 0.5057 - val_loss: 1842.0702 - val_regression_loss: 918.3226 - val_tarreg_loss: 1837.3677 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 372/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4300.4385 - regression_loss: 2147.5103 - tarreg_loss: 4295.7363 - treatment_acc: 0.5057 - val_loss: 1841.9744 - val_regression_loss: 918.2747 - val_tarreg_loss: 1837.2717 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 373/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4298.5073 - regression_loss: 2146.5447 - tarreg_loss: 4293.8047 - treatment_acc: 0.5057 - val_loss: 1841.9436 - val_regression_loss: 918.2594 - val_tarreg_loss: 1837.2411 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 374/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 4296.5718 - regression_loss: 2145.5764 - tarreg_loss: 4291.8691 - treatment_acc: 0.5057 - val_loss: 1841.8557 - val_regression_loss: 918.2155 - val_tarreg_loss: 1837.1533 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 375/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4294.6250 - regression_loss: 2144.6030 - tarreg_loss: 4289.9224 - treatment_acc: 0.5057 - val_loss: 1841.7717 - val_regression_loss: 918.1733 - val_tarreg_loss: 1837.0692 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 376/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4292.7334 - regression_loss: 2143.6572 - tarreg_loss: 4288.0308 - treatment_acc: 0.5057 - val_loss: 1841.7533 - val_regression_loss: 918.1641 - val_tarreg_loss: 1837.0508 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 377/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4290.8267 - regression_loss: 2142.7034 - tarreg_loss: 4286.1240 - treatment_acc: 0.5057 - val_loss: 1841.6946 - val_regression_loss: 918.1348 - val_tarreg_loss: 1836.9921 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 378/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4288.8994 - regression_loss: 2141.7402 - tarreg_loss: 4284.1968 - treatment_acc: 0.5057 - val_loss: 1841.6819 - val_regression_loss: 918.1284 - val_tarreg_loss: 1836.9795 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 379/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4286.9746 - regression_loss: 2140.7778 - tarreg_loss: 4282.2720 - treatment_acc: 0.5057 - val_loss: 1841.5538 - val_regression_loss: 918.0643 - val_tarreg_loss: 1836.8513 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 380/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4285.0264 - regression_loss: 2139.8037 - tarreg_loss: 4280.3237 - treatment_acc: 0.5057 - val_loss: 1841.5104 - val_regression_loss: 918.0426 - val_tarreg_loss: 1836.8079 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 381/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4283.0591 - regression_loss: 2138.8196 - tarreg_loss: 4278.3564 - treatment_acc: 0.5057 - val_loss: 1841.4862 - val_regression_loss: 918.0305 - val_tarreg_loss: 1836.7837 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 382/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4281.1445 - regression_loss: 2137.8623 - tarreg_loss: 4276.4419 - treatment_acc: 0.5054 - val_loss: 1841.4230 - val_regression_loss: 917.9989 - val_tarreg_loss: 1836.7205 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 383/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4279.2632 - regression_loss: 2136.9214 - tarreg_loss: 4274.5605 - treatment_acc: 0.5054 - val_loss: 1841.3577 - val_regression_loss: 917.9663 - val_tarreg_loss: 1836.6553 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 384/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4277.3735 - regression_loss: 2135.9766 - tarreg_loss: 4272.6709 - treatment_acc: 0.5054 - val_loss: 1841.2726 - val_regression_loss: 917.9236 - val_tarreg_loss: 1836.5701 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 385/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4275.4009 - regression_loss: 2134.9902 - tarreg_loss: 4270.6982 - treatment_acc: 0.5054 - val_loss: 1841.2494 - val_regression_loss: 917.9120 - val_tarreg_loss: 1836.5469 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 386/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4273.5366 - regression_loss: 2134.0581 - tarreg_loss: 4268.8340 - treatment_acc: 0.5054 - val_loss: 1841.1659 - val_regression_loss: 917.8702 - val_tarreg_loss: 1836.4634 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 387/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4271.6104 - regression_loss: 2133.0950 - tarreg_loss: 4266.9077 - treatment_acc: 0.5054 - val_loss: 1841.1252 - val_regression_loss: 917.8500 - val_tarreg_loss: 1836.4229 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 388/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4269.7954 - regression_loss: 2132.1875 - tarreg_loss: 4265.0928 - treatment_acc: 0.5054 - val_loss: 1841.0464 - val_regression_loss: 917.8105 - val_tarreg_loss: 1836.3439 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 389/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4267.8149 - regression_loss: 2131.1973 - tarreg_loss: 4263.1123 - treatment_acc: 0.5054 - val_loss: 1840.9745 - val_regression_loss: 917.7745 - val_tarreg_loss: 1836.2720 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 390/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4265.9370 - regression_loss: 2130.2583 - tarreg_loss: 4261.2344 - treatment_acc: 0.5054 - val_loss: 1840.9305 - val_regression_loss: 917.7524 - val_tarreg_loss: 1836.2280 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 391/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4263.9932 - regression_loss: 2129.2861 - tarreg_loss: 4259.2905 - treatment_acc: 0.5057 - val_loss: 1840.8784 - val_regression_loss: 917.7264 - val_tarreg_loss: 1836.1759 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 392/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4262.1421 - regression_loss: 2128.3606 - tarreg_loss: 4257.4395 - treatment_acc: 0.5057 - val_loss: 1840.8508 - val_regression_loss: 917.7126 - val_tarreg_loss: 1836.1482 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 393/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4260.2778 - regression_loss: 2127.4287 - tarreg_loss: 4255.5752 - treatment_acc: 0.5057 - val_loss: 1840.7932 - val_regression_loss: 917.6838 - val_tarreg_loss: 1836.0906 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 394/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4258.3818 - regression_loss: 2126.4805 - tarreg_loss: 4253.6792 - treatment_acc: 0.5057 - val_loss: 1840.7419 - val_regression_loss: 917.6581 - val_tarreg_loss: 1836.0391 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 395/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4256.4829 - regression_loss: 2125.5310 - tarreg_loss: 4251.7803 - treatment_acc: 0.5063 - val_loss: 1840.6892 - val_regression_loss: 917.6316 - val_tarreg_loss: 1835.9863 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 396/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4254.6196 - regression_loss: 2124.5991 - tarreg_loss: 4249.9170 - treatment_acc: 0.5063 - val_loss: 1840.6249 - val_regression_loss: 917.5994 - val_tarreg_loss: 1835.9220 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 397/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4252.7119 - regression_loss: 2123.6453 - tarreg_loss: 4248.0093 - treatment_acc: 0.5063 - val_loss: 1840.6057 - val_regression_loss: 917.5899 - val_tarreg_loss: 1835.9030 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 398/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4250.8174 - regression_loss: 2122.6980 - tarreg_loss: 4246.1147 - treatment_acc: 0.5063 - val_loss: 1840.5437 - val_regression_loss: 917.5588 - val_tarreg_loss: 1835.8408 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 399/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4248.9165 - regression_loss: 2121.7473 - tarreg_loss: 4244.2139 - treatment_acc: 0.5063 - val_loss: 1840.5312 - val_regression_loss: 917.5526 - val_tarreg_loss: 1835.8284 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 400/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4247.0488 - regression_loss: 2120.8132 - tarreg_loss: 4242.3462 - treatment_acc: 0.5063 - val_loss: 1840.4944 - val_regression_loss: 917.5341 - val_tarreg_loss: 1835.7915 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 401/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4245.1797 - regression_loss: 2119.8784 - tarreg_loss: 4240.4771 - treatment_acc: 0.5063 - val_loss: 1840.4327 - val_regression_loss: 917.5033 - val_tarreg_loss: 1835.7300 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 402/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4243.3657 - regression_loss: 2118.9714 - tarreg_loss: 4238.6631 - treatment_acc: 0.5063 - val_loss: 1840.4084 - val_regression_loss: 917.4911 - val_tarreg_loss: 1835.7057 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 403/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4241.4673 - regression_loss: 2118.0225 - tarreg_loss: 4236.7646 - treatment_acc: 0.5063 - val_loss: 1840.3712 - val_regression_loss: 917.4725 - val_tarreg_loss: 1835.6685 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 404/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4239.6401 - regression_loss: 2117.1086 - tarreg_loss: 4234.9375 - treatment_acc: 0.5060 - val_loss: 1840.2963 - val_regression_loss: 917.4350 - val_tarreg_loss: 1835.5935 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 405/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4237.7808 - regression_loss: 2116.1787 - tarreg_loss: 4233.0781 - treatment_acc: 0.5060 - val_loss: 1840.2596 - val_regression_loss: 917.4168 - val_tarreg_loss: 1835.5570 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 406/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 4235.8970 - regression_loss: 2115.2368 - tarreg_loss: 4231.1943 - treatment_acc: 0.5057 - val_loss: 1840.1997 - val_regression_loss: 917.3868 - val_tarreg_loss: 1835.4971 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 407/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4234.0229 - regression_loss: 2114.2998 - tarreg_loss: 4229.3203 - treatment_acc: 0.5057 - val_loss: 1840.1814 - val_regression_loss: 917.3776 - val_tarreg_loss: 1835.4788 - val_treatment_acc: 0.5240 - learning_rate: 6.0000e-08\n","Epoch 408/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4232.1997 - regression_loss: 2113.3882 - tarreg_loss: 4227.4971 - treatment_acc: 0.5057 - val_loss: 1840.1163 - val_regression_loss: 917.3450 - val_tarreg_loss: 1835.4136 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 409/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4230.3325 - regression_loss: 2112.4543 - tarreg_loss: 4225.6299 - treatment_acc: 0.5057 - val_loss: 1840.1063 - val_regression_loss: 917.3400 - val_tarreg_loss: 1835.4038 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 410/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4228.5259 - regression_loss: 2111.5513 - tarreg_loss: 4223.8232 - treatment_acc: 0.5057 - val_loss: 1840.0569 - val_regression_loss: 917.3154 - val_tarreg_loss: 1835.3544 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 411/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4226.6973 - regression_loss: 2110.6365 - tarreg_loss: 4221.9941 - treatment_acc: 0.5057 - val_loss: 1840.0227 - val_regression_loss: 917.2982 - val_tarreg_loss: 1835.3201 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 412/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4224.8037 - regression_loss: 2109.6897 - tarreg_loss: 4220.1006 - treatment_acc: 0.5057 - val_loss: 1840.0042 - val_regression_loss: 917.2889 - val_tarreg_loss: 1835.3015 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 413/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4222.9360 - regression_loss: 2108.7556 - tarreg_loss: 4218.2329 - treatment_acc: 0.5057 - val_loss: 1839.9376 - val_regression_loss: 917.2556 - val_tarreg_loss: 1835.2350 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 414/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4221.1572 - regression_loss: 2107.8662 - tarreg_loss: 4216.4541 - treatment_acc: 0.5057 - val_loss: 1839.9060 - val_regression_loss: 917.2399 - val_tarreg_loss: 1835.2034 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 415/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4219.3062 - regression_loss: 2106.9404 - tarreg_loss: 4214.6025 - treatment_acc: 0.5057 - val_loss: 1839.9031 - val_regression_loss: 917.2383 - val_tarreg_loss: 1835.2004 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 416/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4217.4448 - regression_loss: 2106.0098 - tarreg_loss: 4212.7412 - treatment_acc: 0.5057 - val_loss: 1839.8448 - val_regression_loss: 917.2093 - val_tarreg_loss: 1835.1422 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 417/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4215.5410 - regression_loss: 2105.0579 - tarreg_loss: 4210.8374 - treatment_acc: 0.5057 - val_loss: 1839.8169 - val_regression_loss: 917.1953 - val_tarreg_loss: 1835.1143 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 418/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 4213.7163 - regression_loss: 2104.1455 - tarreg_loss: 4209.0127 - treatment_acc: 0.5060 - val_loss: 1839.7626 - val_regression_loss: 917.1682 - val_tarreg_loss: 1835.0601 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 419/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4211.9829 - regression_loss: 2103.2783 - tarreg_loss: 4207.2793 - treatment_acc: 0.5060 - val_loss: 1839.7151 - val_regression_loss: 917.1443 - val_tarreg_loss: 1835.0125 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 420/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4210.1206 - regression_loss: 2102.3472 - tarreg_loss: 4205.4170 - treatment_acc: 0.5060 - val_loss: 1839.7198 - val_regression_loss: 917.1467 - val_tarreg_loss: 1835.0172 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 421/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4208.3149 - regression_loss: 2101.4443 - tarreg_loss: 4203.6113 - treatment_acc: 0.5060 - val_loss: 1839.6931 - val_regression_loss: 917.1333 - val_tarreg_loss: 1834.9905 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 422/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4206.4663 - regression_loss: 2100.5203 - tarreg_loss: 4201.7627 - treatment_acc: 0.5060 - val_loss: 1839.7200 - val_regression_loss: 917.1466 - val_tarreg_loss: 1835.0173 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 423/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4204.6729 - regression_loss: 2099.6235 - tarreg_loss: 4199.9692 - treatment_acc: 0.5060 - val_loss: 1839.6725 - val_regression_loss: 917.1229 - val_tarreg_loss: 1834.9698 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 424/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4202.8540 - regression_loss: 2098.7141 - tarreg_loss: 4198.1504 - treatment_acc: 0.5060 - val_loss: 1839.6174 - val_regression_loss: 917.0954 - val_tarreg_loss: 1834.9149 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 425/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4201.0366 - regression_loss: 2097.8054 - tarreg_loss: 4196.3330 - treatment_acc: 0.5060 - val_loss: 1839.5955 - val_regression_loss: 917.0844 - val_tarreg_loss: 1834.8928 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 426/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4199.2681 - regression_loss: 2096.9209 - tarreg_loss: 4194.5645 - treatment_acc: 0.5057 - val_loss: 1839.5507 - val_regression_loss: 917.0620 - val_tarreg_loss: 1834.8479 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 427/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4197.3589 - regression_loss: 2095.9663 - tarreg_loss: 4192.6553 - treatment_acc: 0.5057 - val_loss: 1839.5310 - val_regression_loss: 917.0521 - val_tarreg_loss: 1834.8282 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 428/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4195.5479 - regression_loss: 2095.0608 - tarreg_loss: 4190.8442 - treatment_acc: 0.5057 - val_loss: 1839.4967 - val_regression_loss: 917.0349 - val_tarreg_loss: 1834.7939 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 429/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4193.8130 - regression_loss: 2094.1936 - tarreg_loss: 4189.1094 - treatment_acc: 0.5057 - val_loss: 1839.4115 - val_regression_loss: 916.9924 - val_tarreg_loss: 1834.7087 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 430/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 4191.9775 - regression_loss: 2093.2756 - tarreg_loss: 4187.2739 - treatment_acc: 0.5057 - val_loss: 1839.4299 - val_regression_loss: 917.0015 - val_tarreg_loss: 1834.7272 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 431/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4190.1733 - regression_loss: 2092.3735 - tarreg_loss: 4185.4697 - treatment_acc: 0.5057 - val_loss: 1839.4221 - val_regression_loss: 916.9976 - val_tarreg_loss: 1834.7192 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 432/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4188.3716 - regression_loss: 2091.4727 - tarreg_loss: 4183.6680 - treatment_acc: 0.5054 - val_loss: 1839.3934 - val_regression_loss: 916.9831 - val_tarreg_loss: 1834.6904 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 433/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4186.5537 - regression_loss: 2090.5635 - tarreg_loss: 4181.8501 - treatment_acc: 0.5054 - val_loss: 1839.3884 - val_regression_loss: 916.9807 - val_tarreg_loss: 1834.6854 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 434/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4184.7925 - regression_loss: 2089.6831 - tarreg_loss: 4180.0889 - treatment_acc: 0.5054 - val_loss: 1839.3889 - val_regression_loss: 916.9808 - val_tarreg_loss: 1834.6859 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 435/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4182.9419 - regression_loss: 2088.7576 - tarreg_loss: 4178.2383 - treatment_acc: 0.5054 - val_loss: 1839.3517 - val_regression_loss: 916.9622 - val_tarreg_loss: 1834.6487 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 436/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4181.1455 - regression_loss: 2087.8591 - tarreg_loss: 4176.4419 - treatment_acc: 0.5054 - val_loss: 1839.3220 - val_regression_loss: 916.9474 - val_tarreg_loss: 1834.6190 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 437/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4179.3828 - regression_loss: 2086.9780 - tarreg_loss: 4174.6792 - treatment_acc: 0.5051 - val_loss: 1839.3385 - val_regression_loss: 916.9556 - val_tarreg_loss: 1834.6355 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 438/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4177.5845 - regression_loss: 2086.0789 - tarreg_loss: 4172.8809 - treatment_acc: 0.5051 - val_loss: 1839.3430 - val_regression_loss: 916.9578 - val_tarreg_loss: 1834.6400 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 439/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4175.7954 - regression_loss: 2085.1841 - tarreg_loss: 4171.0918 - treatment_acc: 0.5051 - val_loss: 1839.2947 - val_regression_loss: 916.9337 - val_tarreg_loss: 1834.5917 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 440/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4174.0283 - regression_loss: 2084.3005 - tarreg_loss: 4169.3247 - treatment_acc: 0.5051 - val_loss: 1839.2615 - val_regression_loss: 916.9170 - val_tarreg_loss: 1834.5583 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 441/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4172.2690 - regression_loss: 2083.4211 - tarreg_loss: 4167.5654 - treatment_acc: 0.5051 - val_loss: 1839.2595 - val_regression_loss: 916.9160 - val_tarreg_loss: 1834.5564 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 442/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4170.4497 - regression_loss: 2082.5115 - tarreg_loss: 4165.7461 - treatment_acc: 0.5051 - val_loss: 1839.2531 - val_regression_loss: 916.9128 - val_tarreg_loss: 1834.5500 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 443/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4168.6323 - regression_loss: 2081.6028 - tarreg_loss: 4163.9287 - treatment_acc: 0.5051 - val_loss: 1839.2352 - val_regression_loss: 916.9039 - val_tarreg_loss: 1834.5322 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 444/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4166.8413 - regression_loss: 2080.7073 - tarreg_loss: 4162.1377 - treatment_acc: 0.5051 - val_loss: 1839.2023 - val_regression_loss: 916.8875 - val_tarreg_loss: 1834.4993 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 445/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4165.0977 - regression_loss: 2079.8352 - tarreg_loss: 4160.3940 - treatment_acc: 0.5051 - val_loss: 1839.1974 - val_regression_loss: 916.8850 - val_tarreg_loss: 1834.4944 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 446/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4163.3154 - regression_loss: 2078.9441 - tarreg_loss: 4158.6118 - treatment_acc: 0.5051 - val_loss: 1839.2181 - val_regression_loss: 916.8953 - val_tarreg_loss: 1834.5151 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 447/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4161.4956 - regression_loss: 2078.0342 - tarreg_loss: 4156.7920 - treatment_acc: 0.5051 - val_loss: 1839.2112 - val_regression_loss: 916.8920 - val_tarreg_loss: 1834.5083 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 448/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4159.7588 - regression_loss: 2077.1658 - tarreg_loss: 4155.0552 - treatment_acc: 0.5051 - val_loss: 1839.2126 - val_regression_loss: 916.8927 - val_tarreg_loss: 1834.5098 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 449/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 4158.0425 - regression_loss: 2076.3074 - tarreg_loss: 4153.3389 - treatment_acc: 0.5048 - val_loss: 1839.1555 - val_regression_loss: 916.8640 - val_tarreg_loss: 1834.4526 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 450/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 4156.2349 - regression_loss: 2075.4036 - tarreg_loss: 4151.5312 - treatment_acc: 0.5048 - val_loss: 1839.1626 - val_regression_loss: 916.8676 - val_tarreg_loss: 1834.4597 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 451/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4154.4458 - regression_loss: 2074.5090 - tarreg_loss: 4149.7422 - treatment_acc: 0.5048 - val_loss: 1839.1479 - val_regression_loss: 916.8602 - val_tarreg_loss: 1834.4451 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 452/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4152.6567 - regression_loss: 2073.6147 - tarreg_loss: 4147.9531 - treatment_acc: 0.5048 - val_loss: 1839.1365 - val_regression_loss: 916.8546 - val_tarreg_loss: 1834.4336 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 453/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4150.8794 - regression_loss: 2072.7258 - tarreg_loss: 4146.1758 - treatment_acc: 0.5048 - val_loss: 1839.1438 - val_regression_loss: 916.8582 - val_tarreg_loss: 1834.4409 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 454/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4149.1060 - regression_loss: 2071.8391 - tarreg_loss: 4144.4023 - treatment_acc: 0.5045 - val_loss: 1839.1323 - val_regression_loss: 916.8525 - val_tarreg_loss: 1834.4294 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 455/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4147.3813 - regression_loss: 2070.9768 - tarreg_loss: 4142.6777 - treatment_acc: 0.5045 - val_loss: 1839.1096 - val_regression_loss: 916.8412 - val_tarreg_loss: 1834.4067 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 456/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4145.6753 - regression_loss: 2070.1238 - tarreg_loss: 4140.9717 - treatment_acc: 0.5045 - val_loss: 1839.1111 - val_regression_loss: 916.8418 - val_tarreg_loss: 1834.4082 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 457/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4143.8706 - regression_loss: 2069.2214 - tarreg_loss: 4139.1670 - treatment_acc: 0.5045 - val_loss: 1839.1139 - val_regression_loss: 916.8433 - val_tarreg_loss: 1834.4110 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 458/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4142.1577 - regression_loss: 2068.3652 - tarreg_loss: 4137.4541 - treatment_acc: 0.5045 - val_loss: 1839.0634 - val_regression_loss: 916.8180 - val_tarreg_loss: 1834.3606 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 459/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4140.3691 - regression_loss: 2067.4707 - tarreg_loss: 4135.6655 - treatment_acc: 0.5048 - val_loss: 1839.0530 - val_regression_loss: 916.8128 - val_tarreg_loss: 1834.3501 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 460/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4138.6162 - regression_loss: 2066.5942 - tarreg_loss: 4133.9126 - treatment_acc: 0.5048 - val_loss: 1839.0500 - val_regression_loss: 916.8113 - val_tarreg_loss: 1834.3470 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 461/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4136.9136 - regression_loss: 2065.7429 - tarreg_loss: 4132.2100 - treatment_acc: 0.5051 - val_loss: 1839.0862 - val_regression_loss: 916.8293 - val_tarreg_loss: 1834.3833 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 462/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4135.2236 - regression_loss: 2064.8979 - tarreg_loss: 4130.5200 - treatment_acc: 0.5051 - val_loss: 1839.0795 - val_regression_loss: 916.8260 - val_tarreg_loss: 1834.3765 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 463/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 4133.4648 - regression_loss: 2064.0183 - tarreg_loss: 4128.7612 - treatment_acc: 0.5051 - val_loss: 1839.0658 - val_regression_loss: 916.8191 - val_tarreg_loss: 1834.3628 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 464/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4131.7202 - regression_loss: 2063.1460 - tarreg_loss: 4127.0166 - treatment_acc: 0.5051 - val_loss: 1839.0870 - val_regression_loss: 916.8298 - val_tarreg_loss: 1834.3840 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 465/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4129.8872 - regression_loss: 2062.2297 - tarreg_loss: 4125.1836 - treatment_acc: 0.5051 - val_loss: 1839.0873 - val_regression_loss: 916.8298 - val_tarreg_loss: 1834.3843 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 466/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4128.1748 - regression_loss: 2061.3733 - tarreg_loss: 4123.4712 - treatment_acc: 0.5051 - val_loss: 1839.0834 - val_regression_loss: 916.8278 - val_tarreg_loss: 1834.3801 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 467/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4126.4443 - regression_loss: 2060.5081 - tarreg_loss: 4121.7407 - treatment_acc: 0.5051 - val_loss: 1839.0709 - val_regression_loss: 916.8215 - val_tarreg_loss: 1834.3677 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 468/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4124.7246 - regression_loss: 2059.6482 - tarreg_loss: 4120.0210 - treatment_acc: 0.5051 - val_loss: 1839.1014 - val_regression_loss: 916.8367 - val_tarreg_loss: 1834.3982 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 469/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4122.9805 - regression_loss: 2058.7761 - tarreg_loss: 4118.2769 - treatment_acc: 0.5051 - val_loss: 1839.0818 - val_regression_loss: 916.8270 - val_tarreg_loss: 1834.3785 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 470/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4121.2632 - regression_loss: 2057.9175 - tarreg_loss: 4116.5596 - treatment_acc: 0.5051 - val_loss: 1839.0651 - val_regression_loss: 916.8186 - val_tarreg_loss: 1834.3618 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 471/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4119.5425 - regression_loss: 2057.0571 - tarreg_loss: 4114.8389 - treatment_acc: 0.5051 - val_loss: 1839.0382 - val_regression_loss: 916.8051 - val_tarreg_loss: 1834.3350 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 472/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4117.7993 - regression_loss: 2056.1855 - tarreg_loss: 4113.0957 - treatment_acc: 0.5051 - val_loss: 1839.0703 - val_regression_loss: 916.8212 - val_tarreg_loss: 1834.3671 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 473/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4116.0557 - regression_loss: 2055.3140 - tarreg_loss: 4111.3525 - treatment_acc: 0.5051 - val_loss: 1839.0760 - val_regression_loss: 916.8241 - val_tarreg_loss: 1834.3728 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 474/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4114.3315 - regression_loss: 2054.4519 - tarreg_loss: 4109.6284 - treatment_acc: 0.5051 - val_loss: 1839.0865 - val_regression_loss: 916.8293 - val_tarreg_loss: 1834.3833 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 475/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 4112.6025 - regression_loss: 2053.5874 - tarreg_loss: 4107.8994 - treatment_acc: 0.5051 - val_loss: 1839.1272 - val_regression_loss: 916.8497 - val_tarreg_loss: 1834.4241 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 476/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4110.8398 - regression_loss: 2052.7061 - tarreg_loss: 4106.1367 - treatment_acc: 0.5051 - val_loss: 1839.1018 - val_regression_loss: 916.8370 - val_tarreg_loss: 1834.3987 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 477/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4109.1250 - regression_loss: 2051.8486 - tarreg_loss: 4104.4219 - treatment_acc: 0.5051 - val_loss: 1839.1063 - val_regression_loss: 916.8391 - val_tarreg_loss: 1834.4031 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 478/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4107.3989 - regression_loss: 2050.9856 - tarreg_loss: 4102.6958 - treatment_acc: 0.5048 - val_loss: 1839.1228 - val_regression_loss: 916.8474 - val_tarreg_loss: 1834.4196 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 479/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4105.7134 - regression_loss: 2050.1428 - tarreg_loss: 4101.0103 - treatment_acc: 0.5048 - val_loss: 1839.1067 - val_regression_loss: 916.8394 - val_tarreg_loss: 1834.4034 - val_treatment_acc: 0.5228 - learning_rate: 6.0000e-08\n","Epoch 480/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4103.9814 - regression_loss: 2049.2769 - tarreg_loss: 4099.2783 - treatment_acc: 0.5048 - val_loss: 1839.1376 - val_regression_loss: 916.8548 - val_tarreg_loss: 1834.4343 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 481/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4102.2734 - regression_loss: 2048.4226 - tarreg_loss: 4097.5703 - treatment_acc: 0.5048 - val_loss: 1839.1444 - val_regression_loss: 916.8582 - val_tarreg_loss: 1834.4412 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 482/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4100.5469 - regression_loss: 2047.5593 - tarreg_loss: 4095.8438 - treatment_acc: 0.5048 - val_loss: 1839.1124 - val_regression_loss: 916.8423 - val_tarreg_loss: 1834.4092 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 483/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4098.8203 - regression_loss: 2046.6959 - tarreg_loss: 4094.1167 - treatment_acc: 0.5048 - val_loss: 1839.1296 - val_regression_loss: 916.8508 - val_tarreg_loss: 1834.4264 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 484/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4097.1191 - regression_loss: 2045.8456 - tarreg_loss: 4092.4160 - treatment_acc: 0.5048 - val_loss: 1839.1593 - val_regression_loss: 916.8656 - val_tarreg_loss: 1834.4561 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 485/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 4095.3787 - regression_loss: 2044.9751 - tarreg_loss: 4090.6753 - treatment_acc: 0.5045 - val_loss: 1839.1819 - val_regression_loss: 916.8770 - val_tarreg_loss: 1834.4788 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 486/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4093.7556 - regression_loss: 2044.1637 - tarreg_loss: 4089.0522 - treatment_acc: 0.5048 - val_loss: 1839.1803 - val_regression_loss: 916.8761 - val_tarreg_loss: 1834.4771 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 487/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4092.0093 - regression_loss: 2043.2905 - tarreg_loss: 4087.3059 - treatment_acc: 0.5045 - val_loss: 1839.1858 - val_regression_loss: 916.8788 - val_tarreg_loss: 1834.4825 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 488/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4090.3152 - regression_loss: 2042.4434 - tarreg_loss: 4085.6118 - treatment_acc: 0.5045 - val_loss: 1839.2018 - val_regression_loss: 916.8869 - val_tarreg_loss: 1834.4985 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 489/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 4088.6243 - regression_loss: 2041.5979 - tarreg_loss: 4083.9209 - treatment_acc: 0.5045 - val_loss: 1839.2542 - val_regression_loss: 916.9131 - val_tarreg_loss: 1834.5510 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 490/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4086.8799 - regression_loss: 2040.7258 - tarreg_loss: 4082.1765 - treatment_acc: 0.5045 - val_loss: 1839.2610 - val_regression_loss: 916.9165 - val_tarreg_loss: 1834.5576 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 491/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4085.1843 - regression_loss: 2039.8779 - tarreg_loss: 4080.4810 - treatment_acc: 0.5042 - val_loss: 1839.2498 - val_regression_loss: 916.9107 - val_tarreg_loss: 1834.5464 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 492/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4083.4714 - regression_loss: 2039.0215 - tarreg_loss: 4078.7681 - treatment_acc: 0.5045 - val_loss: 1839.2748 - val_regression_loss: 916.9233 - val_tarreg_loss: 1834.5714 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 493/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 4081.7263 - regression_loss: 2038.1490 - tarreg_loss: 4077.0229 - treatment_acc: 0.5045 - val_loss: 1839.3127 - val_regression_loss: 916.9423 - val_tarreg_loss: 1834.6095 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 494/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4079.9963 - regression_loss: 2037.2839 - tarreg_loss: 4075.2930 - treatment_acc: 0.5045 - val_loss: 1839.3137 - val_regression_loss: 916.9427 - val_tarreg_loss: 1834.6104 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 495/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4078.3523 - regression_loss: 2036.4619 - tarreg_loss: 4073.6489 - treatment_acc: 0.5042 - val_loss: 1839.3289 - val_regression_loss: 916.9503 - val_tarreg_loss: 1834.6255 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 496/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 4076.6511 - regression_loss: 2035.6113 - tarreg_loss: 4071.9478 - treatment_acc: 0.5042 - val_loss: 1839.3313 - val_regression_loss: 916.9515 - val_tarreg_loss: 1834.6279 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 497/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 4074.9641 - regression_loss: 2034.7677 - tarreg_loss: 4070.2607 - treatment_acc: 0.5042 - val_loss: 1839.3276 - val_regression_loss: 916.9497 - val_tarreg_loss: 1834.6243 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 498/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 4073.2781 - regression_loss: 2033.9246 - tarreg_loss: 4068.5745 - treatment_acc: 0.5042 - val_loss: 1839.3553 - val_regression_loss: 916.9635 - val_tarreg_loss: 1834.6520 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 499/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4071.5876 - regression_loss: 2033.0795 - tarreg_loss: 4066.8843 - treatment_acc: 0.5045 - val_loss: 1839.3854 - val_regression_loss: 916.9785 - val_tarreg_loss: 1834.6819 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 500/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4069.9153 - regression_loss: 2032.2432 - tarreg_loss: 4065.2117 - treatment_acc: 0.5045 - val_loss: 1839.3873 - val_regression_loss: 916.9794 - val_tarreg_loss: 1834.6838 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 501/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 4068.2205 - regression_loss: 2031.3959 - tarreg_loss: 4063.5171 - treatment_acc: 0.5045 - val_loss: 1839.4148 - val_regression_loss: 916.9931 - val_tarreg_loss: 1834.7112 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 502/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4066.5398 - regression_loss: 2030.5557 - tarreg_loss: 4061.8364 - treatment_acc: 0.5045 - val_loss: 1839.4106 - val_regression_loss: 916.9910 - val_tarreg_loss: 1834.7070 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 503/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 4064.8757 - regression_loss: 2029.7235 - tarreg_loss: 4060.1724 - treatment_acc: 0.5045 - val_loss: 1839.4576 - val_regression_loss: 917.0145 - val_tarreg_loss: 1834.7540 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 504/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4063.1545 - regression_loss: 2028.8629 - tarreg_loss: 4058.4512 - treatment_acc: 0.5045 - val_loss: 1839.4570 - val_regression_loss: 917.0143 - val_tarreg_loss: 1834.7534 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 505/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 4061.4265 - regression_loss: 2027.9988 - tarreg_loss: 4056.7231 - treatment_acc: 0.5045 - val_loss: 1839.5063 - val_regression_loss: 917.0389 - val_tarreg_loss: 1834.8027 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 506/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 4059.7666 - regression_loss: 2027.1689 - tarreg_loss: 4055.0632 - treatment_acc: 0.5045 - val_loss: 1839.5159 - val_regression_loss: 917.0436 - val_tarreg_loss: 1834.8123 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 507/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 4058.0842 - regression_loss: 2026.3276 - tarreg_loss: 4053.3806 - treatment_acc: 0.5045 - val_loss: 1839.5278 - val_regression_loss: 917.0496 - val_tarreg_loss: 1834.8242 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 508/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 4056.4919 - regression_loss: 2025.5315 - tarreg_loss: 4051.7883 - treatment_acc: 0.5045 - val_loss: 1839.5376 - val_regression_loss: 917.0545 - val_tarreg_loss: 1834.8340 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 509/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 4054.7434 - regression_loss: 2024.6573 - tarreg_loss: 4050.0398 - treatment_acc: 0.5042 - val_loss: 1839.6233 - val_regression_loss: 917.0973 - val_tarreg_loss: 1834.9197 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 510/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 4053.0225 - regression_loss: 2023.7968 - tarreg_loss: 4048.3188 - treatment_acc: 0.5045 - val_loss: 1839.6350 - val_regression_loss: 917.1033 - val_tarreg_loss: 1834.9315 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","Epoch 511/100000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 4051.3340 - regression_loss: 2022.9526 - tarreg_loss: 4046.6304 - treatment_acc: 0.5045 - val_loss: 1839.6331 - val_regression_loss: 917.1024 - val_tarreg_loss: 1834.9296 - val_treatment_acc: 0.5216 - learning_rate: 6.0000e-08\n","\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n","tf.Tensor([1040 1040], shape=(2,), dtype=int32)\n"]}],"source":["from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau, TerminateOnNaN\n","from tensorflow.keras.optimizers import SGD, Adam\n","import io\n","from IPython.display import display, clear_output\n","#Colab command to allow us to run Colab in TF2\n","%load_ext tensorboard\n","# data=get_news_data(1)\n","val_split=0.20\n","batch_size=4000\n","verbose=1\n","i = 0\n","tf.random.set_seed(i)\n","np.random.seed(i)\n","!rm -rf ./logs_dragonnet/\n","sim_evals = []\n","for j in range(0,10):\n","  clear_output(wait=True)\n","  print(j+1)\n","  data_train, data_test = load_data(dataset=\"BlogCatalog\", kappa=2, exp_id=j)\n","  yt = np.concatenate([data_train['ys'], data_train['t']], 1)\n","\n","  # Clear any logs from previous runs\n","\n","  start_time = time.time()\n","\n","  log_dir = \"logs_dragonnet/fit/\" +str(j)+\"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n","  file_writer.set_as_default()\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n","\n","  print(data_train['x'])\n","\n","\n","  sgd_callbacks = [\n","        TerminateOnNaN(),\n","        EarlyStopping(monitor='val_loss', patience=40, min_delta=0.),\n","        ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n","                          min_delta=0., cooldown=0, min_lr=0),\n","        tensorboard_callback]\n","\n","  # sgd_lr = 0.00001 # Flickr\n","  sgd_lr = 0.00000006 # BlogCat\n","  momentum = 0.9\n","\n","  dragonnet_model=make_dragonnet(data_train['x'].shape[1],.01)\n","  tarreg_loss=TarReg_Loss(alpha=1)\n","\n","  dragonnet_model.compile(optimizer=SGD(learning_rate=sgd_lr, momentum=momentum, nesterov=True),\n","                      loss=tarreg_loss,\n","                 metrics=[tarreg_loss,tarreg_loss.regression_loss,tarreg_loss.treatment_acc])\n","\n","  dragonnet_model.fit(x=data_train['x'],y=yt,\n","                 callbacks=sgd_callbacks,\n","                  validation_split=val_split,\n","                  epochs=100000,\n","                  batch_size=batch_size,\n","                  verbose=verbose)\n","  end_time = time.time()\n","\n","  elapsed_time_seconds = end_time - start_time\n","  # Convert elapsed time to minutes\n","  elapsed_time_minutes = elapsed_time_seconds / 60\n","\n","  Evaluation_metrics_insample = Eval_metrics_train(data_train)\n","  concat_pred_insample = dragonnet_model.predict(data_train['x'])\n","  ATE_abs_insample = Evaluation_metrics_insample.ATE_absolute_error(concat_pred_insample)\n","  ATE_TARREG_insample = Evaluation_metrics_insample.TARREG_ATE_absolute_error(concat_pred_insample)\n","  ITE_RMSE_insample = Evaluation_metrics_insample.ITE_RMSE_error(concat_pred_insample)\n","\n","  Evaluation_metrics_outsample = Eval_metrics_test(data_test)\n","  concat_pred_outsample = dragonnet_model.predict(data_test['x'])\n","  ATE_TARREG_outsample = Evaluation_metrics_outsample.TARREG_ATE_absolute_error(concat_pred_outsample)\n","  PEHE_outsample = Evaluation_metrics_outsample.PEHE(concat_pred_outsample)\n","  PEHE_tareg_outsample = Evaluation_metrics_outsample.PEHE_tareg(concat_pred_outsample)\n","\n","  metrics = [ATE_abs_insample.numpy(), ATE_TARREG_insample.numpy(), ITE_RMSE_insample.numpy(), ATE_TARREG_outsample.numpy(), PEHE_outsample.numpy(), PEHE_tareg_outsample.numpy(), elapsed_time_minutes]\n","  sim_evals.append(metrics)"]},{"cell_type":"code","source":[],"metadata":{"id":"zWCP87936rnA","executionInfo":{"status":"ok","timestamp":1725484236616,"user_tz":240,"elapsed":18,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"id":"zWCP87936rnA","execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"id":"01a697a4","metadata":{"id":"01a697a4","executionInfo":{"status":"ok","timestamp":1725484236616,"user_tz":240,"elapsed":17,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[],"source":["sim_evals = np.asarray(sim_evals)\n","# with open('eval_metrics_news_20.npy', 'wb') as f:\n","#     np.save(f,sim_evals)"]},{"cell_type":"code","execution_count":21,"id":"dda9573c","metadata":{"id":"dda9573c","outputId":"c4a4340f-88b6-4403-c4d6-fbbbf3bfc951","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725484236616,"user_tz":240,"elapsed":16,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[" Insample ATE error for Dragonnet(mean over 10) = 4.21 +- 1.03\n"," Insample ATE targ_reg error for Dragonnet(mean over 10) = 3.94 +- 0.96\n"," Insample ITE_RMSE error for Dragonnet(mean over 10) = 24.05 +- 0.37\n"," Outsample ATE targ_reg error for Dragonnet(mean over 10) = 3.81 +- 1.0\n"," Outsample PEHE error for Dragonnet(mean over 10) = 23.03 +- 2.58\n"," Outsample PEHE targ_reg error for Dragonnet(mean over 10) = 23.16 +- 2.6\n"," Wall time for TARNET(sum over 10) = 9.218615098794302\n"]}],"source":["# [ATE_abs_insample.numpy(), ATE_TARREG_insample.numpy(), ITE_RMSE_insample.numpy(), ATE_TARREG_outsample.numpy(), PEHE_outsample.numpy(), PEHE_tareg_outsample.numpy(), elapsed_time_minutes\n","\n","print(\" Insample ATE error for Dragonnet(mean over 10) =\", round(np.mean(sim_evals[:,0]),2),\"+-\",round((np.std(sim_evals[:,0], ddof=1) / np.sqrt(np.size(sim_evals[:,0]))),2))\n","print(\" Insample ATE targ_reg error for Dragonnet(mean over 10) =\", round(np.mean(sim_evals[:,1]),2),\"+-\",round((np.std(sim_evals[:,1], ddof=1) / np.sqrt(np.size(sim_evals[:,1]))),2))\n","print(\" Insample ITE_RMSE error for Dragonnet(mean over 10) =\", round(np.mean(sim_evals[:,2]),2),\"+-\",round((np.std(sim_evals[:,2], ddof=1) / np.sqrt(np.size(sim_evals[:,2]))),2))\n","print(\" Outsample ATE targ_reg error for Dragonnet(mean over 10) =\", round(np.mean(sim_evals[:,3]),2),\"+-\",round((np.std(sim_evals[:,3], ddof=1) / np.sqrt(np.size(sim_evals[:,3]))),2))\n","print(\" Outsample PEHE error for Dragonnet(mean over 10) =\", round(np.mean(sim_evals[:,4]),2),\"+-\",round((np.std(sim_evals[:,4], ddof=1) / np.sqrt(np.size(sim_evals[:,4]))),2))\n","print(\" Outsample PEHE targ_reg error for Dragonnet(mean over 10) =\", round(np.mean(sim_evals[:,5]),2),\"+-\",round((np.std(sim_evals[:,5], ddof=1) / np.sqrt(np.size(sim_evals[:,5]))),2))\n","print(\" Wall time for TARNET(sum over 10) =\", np.sum(sim_evals[:,6]))"]},{"cell_type":"code","execution_count":18,"id":"89e2239e","metadata":{"id":"89e2239e","outputId":"e9a7b892-3d02-4d76-dcff-25fd1c20495f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725483589234,"user_tz":240,"elapsed":4,"user":{"displayName":"Abhishek Dalvi","userId":"01466421205583090743"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 13723987066099933871\n"," xla_global_id: -1,\n"," name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 40427651072\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 2617528058496593902\n"," physical_device_desc: \"device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":18}],"source":["from tensorflow.python.client import device_lib\n","\n","device_lib.list_local_devices()"]},{"cell_type":"code","execution_count":null,"id":"745a58d7","metadata":{"id":"745a58d7"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}